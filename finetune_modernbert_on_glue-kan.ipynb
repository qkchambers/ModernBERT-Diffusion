{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started with ModernBERT & GLUE\n",
    "\n",
    "Created by: [Wayde Gilliam](https://twitter.com/waydegilliam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoders Strike Back!\n",
    "\n",
    "Like many, I have fond memories of finetuning deberta, roberta and bert models for a number of Kaggle comps and real-world problems (e.g., NER, sentiment analysis, etc.).  Encoder models were \"the thing\" back in the day and continue to be the primary workhorse for many ML pipelines today though they have been eclipsed by recent advancements in LLMs which typically are based on decoder-only architectures. Long have we awaited a return to an encoder model for the modern world. With ModernBERT, that wait is over! ModernBERT is a new encoder-only model that incorporates the latest features in making neural networks more efficient, faster, and better at handling tasks that encoder models have long excelled at such at text classification.  In addition, ModernBERT allows us to break out of that max 512 token limit with their long context capabilities which give us 8,192 tokens to play with.\n",
    "\n",
    "In this tutorial, we'll go through the steps of fine-tuning ModernBERT for one of the GLUE tasks, MRPC.  We'll cover some key settings required to use it with the HuggingFace trainer and include with some recommended hyperparameters that have served us well in fine-tuning ModernBERT for GLUE.  We'll also see how to use the model for inference and cleanup the model from the GPU to free up resources.\n",
    "\n",
    "As an aside, I'm running all this code on a single 3090 with plenty of GPU memory to spare.\n",
    "\n",
    "Though not strictly necessary, **ModernBERT trains better with FlashAttention!**. Training and inference will be much faster with it installed. See below:\n",
    "\n",
    "ModernBERT is built on top of FlashAttention which is a highly optimized implementation of the attention mechanism that is faster and more memory efficient than the standard implementation.  ***The beauty of this is all you need to do is install it for ModernBERT to work with it!***  Here's how ...\n",
    "\n",
    "For NVIDIA GPUs with compute capability 8.0+ (Ampere/Ada/Hopper architecture - A100, A6000, RTX 3090, RTX 4090, H100 etc):\n",
    "```python\n",
    "pip install flash-attn --no-build-isolation\n",
    "```\n",
    "\n",
    "For older NVIDIA GPUs (pre-Ampere):\n",
    "```python\n",
    "pip install flash-attn --no-deps\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install setuptools transformers datasets accelerate scikit-learn -Uqq\n",
    "# install setuptools and do this before installing flash-attn\n",
    "# pip install flash-attn --no-build-isolation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/development/ModernBERT/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from functools import partial\n",
    "import gc\n",
    "\n",
    "from datasets import load_dataset\n",
    "from sklearn.metrics import f1_score\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    DataCollatorWithPadding,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    TrainerCallback,\n",
    ")\n",
    "\n",
    "from sklearn.metrics import matthews_corrcoef, accuracy_score, f1_score\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is GLUE?\n",
    "\n",
    "The [General Language Understanding Evaluation (GLUE) benchmark](https://gluebenchmark.com/) is a collection of nine diverse natural language understanding tasks designed to evaluate and compare the performance of NLP models across various language comprehension challenges. By providing a standardized framework, GLUE facilitates the development of models that generalize well across multiple tasks, promoting advancements in creating robust and versatile language understanding systems. \n",
    "\n",
    "Let's put this all these tasks in a dictionary along with some other helpful metadata about each one that might prove useful to iteratting over all of them.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_b4559_row0_col0, #T_b4559_row0_col1, #T_b4559_row0_col2, #T_b4559_row0_col3, #T_b4559_row0_col4, #T_b4559_row0_col5, #T_b4559_row1_col0, #T_b4559_row1_col1, #T_b4559_row1_col2, #T_b4559_row1_col3, #T_b4559_row1_col4, #T_b4559_row1_col5, #T_b4559_row2_col0, #T_b4559_row2_col1, #T_b4559_row2_col2, #T_b4559_row2_col3, #T_b4559_row2_col4, #T_b4559_row2_col5, #T_b4559_row3_col0, #T_b4559_row3_col1, #T_b4559_row3_col2, #T_b4559_row3_col3, #T_b4559_row3_col4, #T_b4559_row3_col5, #T_b4559_row4_col0, #T_b4559_row4_col1, #T_b4559_row4_col2, #T_b4559_row4_col3, #T_b4559_row4_col4, #T_b4559_row4_col5, #T_b4559_row5_col0, #T_b4559_row5_col1, #T_b4559_row5_col2, #T_b4559_row5_col3, #T_b4559_row5_col4, #T_b4559_row5_col5, #T_b4559_row6_col0, #T_b4559_row6_col1, #T_b4559_row6_col2, #T_b4559_row6_col3, #T_b4559_row6_col4, #T_b4559_row6_col5 {\n",
       "  text-align: left;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_b4559\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_b4559_level0_col0\" class=\"col_heading level0 col0\" >Abbr</th>\n",
       "      <th id=\"T_b4559_level0_col1\" class=\"col_heading level0 col1\" >Name</th>\n",
       "      <th id=\"T_b4559_level0_col2\" class=\"col_heading level0 col2\" >Task type</th>\n",
       "      <th id=\"T_b4559_level0_col3\" class=\"col_heading level0 col3\" >Description</th>\n",
       "      <th id=\"T_b4559_level0_col4\" class=\"col_heading level0 col4\" >Size</th>\n",
       "      <th id=\"T_b4559_level0_col5\" class=\"col_heading level0 col5\" >Metrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_b4559_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_b4559_row0_col0\" class=\"data row0 col0\" >SST-B</td>\n",
       "      <td id=\"T_b4559_row0_col1\" class=\"data row0 col1\" >Semantic Textual Similarity Benchmark</td>\n",
       "      <td id=\"T_b4559_row0_col2\" class=\"data row0 col2\" >Similarity and Paraphrase Tasks</td>\n",
       "      <td id=\"T_b4559_row0_col3\" class=\"data row0 col3\" >Predict the similarity score for two sentences on a scale from 1 to 5</td>\n",
       "      <td id=\"T_b4559_row0_col4\" class=\"data row0 col4\" >7k</td>\n",
       "      <td id=\"T_b4559_row0_col5\" class=\"data row0 col5\" >Pearson/Spearman corr.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b4559_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_b4559_row1_col0\" class=\"data row1 col0\" >QQP</td>\n",
       "      <td id=\"T_b4559_row1_col1\" class=\"data row1 col1\" >Quora question pair</td>\n",
       "      <td id=\"T_b4559_row1_col2\" class=\"data row1 col2\" >Similarity and Paraphrase Tasks</td>\n",
       "      <td id=\"T_b4559_row1_col3\" class=\"data row1 col3\" >Predict if two questions are a paraphrase of one another</td>\n",
       "      <td id=\"T_b4559_row1_col4\" class=\"data row1 col4\" >364k</td>\n",
       "      <td id=\"T_b4559_row1_col5\" class=\"data row1 col5\" >F1/Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b4559_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_b4559_row2_col0\" class=\"data row2 col0\" >MNLI</td>\n",
       "      <td id=\"T_b4559_row2_col1\" class=\"data row2 col1\" >Mulit-Genre Natural Language Inference</td>\n",
       "      <td id=\"T_b4559_row2_col2\" class=\"data row2 col2\" >Inference Tasks</td>\n",
       "      <td id=\"T_b4559_row2_col3\" class=\"data row2 col3\" >Predict whether the premise entails, contradicts or is neutral to the hypothesis</td>\n",
       "      <td id=\"T_b4559_row2_col4\" class=\"data row2 col4\" >393k</td>\n",
       "      <td id=\"T_b4559_row2_col5\" class=\"data row2 col5\" >Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b4559_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_b4559_row3_col0\" class=\"data row3 col0\" >MNLI</td>\n",
       "      <td id=\"T_b4559_row3_col1\" class=\"data row3 col1\" >Mulit-Genre Natural Language Inference</td>\n",
       "      <td id=\"T_b4559_row3_col2\" class=\"data row3 col2\" >Inference Tasks</td>\n",
       "      <td id=\"T_b4559_row3_col3\" class=\"data row3 col3\" >Predict whether the premise entails, contradicts or is neutral to the hypothesis</td>\n",
       "      <td id=\"T_b4559_row3_col4\" class=\"data row3 col4\" >393k</td>\n",
       "      <td id=\"T_b4559_row3_col5\" class=\"data row3 col5\" >Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b4559_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_b4559_row4_col0\" class=\"data row4 col0\" >QNLI</td>\n",
       "      <td id=\"T_b4559_row4_col1\" class=\"data row4 col1\" >Stanford Question Answering Dataset</td>\n",
       "      <td id=\"T_b4559_row4_col2\" class=\"data row4 col2\" >Inference Tasks</td>\n",
       "      <td id=\"T_b4559_row4_col3\" class=\"data row4 col3\" >Predict whether the context sentence contains the answer to the question</td>\n",
       "      <td id=\"T_b4559_row4_col4\" class=\"data row4 col4\" >105k</td>\n",
       "      <td id=\"T_b4559_row4_col5\" class=\"data row4 col5\" >Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b4559_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_b4559_row5_col0\" class=\"data row5 col0\" >RTE</td>\n",
       "      <td id=\"T_b4559_row5_col1\" class=\"data row5 col1\" >Recognize Textual Entailment</td>\n",
       "      <td id=\"T_b4559_row5_col2\" class=\"data row5 col2\" >Inference Tasks</td>\n",
       "      <td id=\"T_b4559_row5_col3\" class=\"data row5 col3\" >Predict whether one sentece entails another</td>\n",
       "      <td id=\"T_b4559_row5_col4\" class=\"data row5 col4\" >2.5k</td>\n",
       "      <td id=\"T_b4559_row5_col5\" class=\"data row5 col5\" >Accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b4559_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_b4559_row6_col0\" class=\"data row6 col0\" >WNLI</td>\n",
       "      <td id=\"T_b4559_row6_col1\" class=\"data row6 col1\" >Winograd Schema Challenge</td>\n",
       "      <td id=\"T_b4559_row6_col2\" class=\"data row6 col2\" >Inference Tasks</td>\n",
       "      <td id=\"T_b4559_row6_col3\" class=\"data row6 col3\" >Predict if the sentence with the pronoun substituted is entailed by the original sentence</td>\n",
       "      <td id=\"T_b4559_row6_col4\" class=\"data row6 col4\" >634</td>\n",
       "      <td id=\"T_b4559_row6_col5\" class=\"data row6 col5\" >Accuracy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x729a7da37390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "glue_tasks = {\n",
    "\n",
    "    \"stsb\": {\n",
    "        \"abbr\": \"SST-B\",\n",
    "        \"name\": \"Semantic Textual Similarity Benchmark\",\n",
    "        \"description\": \"Predict the similarity score for two sentences on a scale from 1 to 5\",\n",
    "        \"task_type\": \"Similarity and Paraphrase Tasks\",\n",
    "        \"domain\": \"Misc.\",\n",
    "        \"size\": \"7k\",\n",
    "        \"metrics\": \"Pearson/Spearman corr.\",\n",
    "        \"dataset_names\": {\"train\": \"train\", \"valid\": \"validation\", \"test\": \"test\"},\n",
    "        \"inputs\": [\"sentence1\", \"sentence2\"],\n",
    "        \"target\": \"label\",\n",
    "        \"metric_funcs\": [pearsonr, spearmanr],\n",
    "        \"n_labels\": 1,\n",
    "    },\n",
    "    \"qqp\": {\n",
    "        \"abbr\": \"QQP\",\n",
    "        \"name\": \"Quora question pair\",\n",
    "        \"description\": \"Predict if two questions are a paraphrase of one another\",\n",
    "        \"task_type\": \"Similarity and Paraphrase Tasks\",\n",
    "        \"domain\": \"Social QA questions\",\n",
    "        \"size\": \"364k\",\n",
    "        \"metrics\": \"F1/Accuracy\",\n",
    "        \"dataset_names\": {\"train\": \"train\", \"valid\": \"validation\", \"test\": \"test\"},\n",
    "        \"inputs\": [\"question1\", \"question2\"],\n",
    "        \"target\": \"label\",\n",
    "        \"metric_funcs\": [f1_score, accuracy_score],\n",
    "        \"n_labels\": 2,\n",
    "    },\n",
    "    \"mnli-matched\": {\n",
    "        \"abbr\": \"MNLI\",\n",
    "        \"name\": \"Mulit-Genre Natural Language Inference\",\n",
    "        \"description\": \"Predict whether the premise entails, contradicts or is neutral to the hypothesis\",\n",
    "        \"task_type\": \"Inference Tasks\",\n",
    "        \"domain\": \"Misc.\",\n",
    "        \"size\": \"393k\",\n",
    "        \"metrics\": \"Accuracy\",\n",
    "        \"dataset_names\": {\"train\": \"train\", \"valid\": \"validation_matched\", \"test\": \"test_matched\"},\n",
    "        \"inputs\": [\"premise\", \"hypothesis\"],\n",
    "        \"target\": \"label\",\n",
    "        \"metric_funcs\": [accuracy_score],\n",
    "        \"n_labels\": 3,\n",
    "    },\n",
    "    \"mnli-mismatched\": {\n",
    "        \"abbr\": \"MNLI\",\n",
    "        \"name\": \"Mulit-Genre Natural Language Inference\",\n",
    "        \"description\": \"Predict whether the premise entails, contradicts or is neutral to the hypothesis\",\n",
    "        \"task_type\": \"Inference Tasks\",\n",
    "        \"domain\": \"Misc.\",\n",
    "        \"size\": \"393k\",\n",
    "        \"metrics\": \"Accuracy\",\n",
    "        \"dataset_names\": {\"train\": \"train\", \"valid\": \"validation_mismatched\", \"test\": \"test_mismatched\"},\n",
    "        \"inputs\": [\"premise\", \"hypothesis\"],\n",
    "        \"target\": \"label\",\n",
    "        \"metric_funcs\": [accuracy_score],\n",
    "        \"n_labels\": 3,\n",
    "    },\n",
    "    \"qnli\": {\n",
    "        \"abbr\": \"QNLI\",\n",
    "        \"name\": \"Stanford Question Answering Dataset\",\n",
    "        \"description\": \"Predict whether the context sentence contains the answer to the question\",\n",
    "        \"task_type\": \"Inference Tasks\",\n",
    "        \"domain\": \"Wikipedia\",\n",
    "        \"size\": \"105k\",\n",
    "        \"metrics\": \"Accuracy\",\n",
    "        \"dataset_names\": {\"train\": \"train\", \"valid\": \"validation\", \"test\": \"test\"},\n",
    "        \"inputs\": [\"question\", \"sentence\"],\n",
    "        \"target\": \"label\",\n",
    "        \"metric_funcs\": [accuracy_score],\n",
    "        \"n_labels\": 2,\n",
    "    },\n",
    "    \"rte\": {\n",
    "        \"abbr\": \"RTE\",\n",
    "        \"name\": \"Recognize Textual Entailment\",\n",
    "        \"description\": \"Predict whether one sentece entails another\",\n",
    "        \"task_type\": \"Inference Tasks\",\n",
    "        \"domain\": \"News, Wikipedia\",\n",
    "        \"size\": \"2.5k\",\n",
    "        \"metrics\": \"Accuracy\",\n",
    "        \"dataset_names\": {\"train\": \"train\", \"valid\": \"validation\", \"test\": \"test\"},\n",
    "        \"inputs\": [\"sentence1\", \"sentence2\"],\n",
    "        \"target\": \"label\",\n",
    "        \"metric_funcs\": [accuracy_score],\n",
    "        \"n_labels\": 2,\n",
    "    },\n",
    "    \"wnli\": {\n",
    "        \"abbr\": \"WNLI\",\n",
    "        \"name\": \"Winograd Schema Challenge\",\n",
    "        \"description\": \"Predict if the sentence with the pronoun substituted is entailed by the original sentence\",\n",
    "        \"task_type\": \"Inference Tasks\",\n",
    "        \"domain\": \"Fiction books\",\n",
    "        \"size\": \"634\",\n",
    "        \"metrics\": \"Accuracy\",\n",
    "        \"dataset_names\": {\"train\": \"train\", \"valid\": \"validation\", \"test\": \"test\"},\n",
    "        \"inputs\": [\"sentence1\", \"sentence2\"],\n",
    "        \"target\": \"label\",\n",
    "        \"metric_funcs\": [accuracy_score],\n",
    "        \"n_labels\": 2,\n",
    "    },\n",
    "}\n",
    "\n",
    "# for v in glue_tasks.values(): print(v)\n",
    "glue_tasks.values()\n",
    "\n",
    "glue_df = pd.DataFrame(glue_tasks.values(), columns=[\"abbr\", \"name\", \"task_type\", \"description\", \"size\", \"metrics\"])\n",
    "glue_df.columns = glue_df.columns.str.replace(\"_\", \" \").str.capitalize()\n",
    "display(glue_df.style.set_properties(**{\"text-align\": \"left\"}))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's Fine-Tune ModernBERT for MRPC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration\n",
    "\n",
    "ModernBERT currently comes in two flavors, base and large. To keep things lean and mean, we'll use the \"answerdotai/ModernBERT-base\" checkpoint for this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = \"mrpc\"\n",
    "task_meta = glue_tasks[task]\n",
    "train_ds_name = task_meta[\"dataset_names\"][\"train\"]\n",
    "valid_ds_name = task_meta[\"dataset_names\"][\"valid\"]\n",
    "test_ds_name = task_meta[\"dataset_names\"][\"test\"]\n",
    "\n",
    "task_inputs = task_meta[\"inputs\"]\n",
    "task_target = task_meta[\"target\"]\n",
    "n_labels = task_meta[\"n_labels\"]\n",
    "task_metrics = task_meta[\"metric_funcs\"]\n",
    "\n",
    "checkpoint = \"output_model/modernbert-diffusion-1b\"  # \"answerdotai/ModernBERT-base\", \"answerdotai/ModernBERT-large\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use the `Datasets` library to load the data.  As its always recommended to \"look at your data\" before we get training, we'll also print out a single example to see what we're working with as well as the features of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
      "        num_rows: 3668\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
      "        num_rows: 408\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
      "        num_rows: 1725\n",
      "    })\n",
      "})\n",
      "\n",
      "{'sentence1': 'Amrozi accused his brother , whom he called \" the witness \" , of deliberately distorting his evidence .', 'sentence2': 'Referring to him as only \" the witness \" , Amrozi accused his brother of deliberately distorting his evidence .', 'label': 1, 'idx': 0}\n",
      "\n",
      "{'sentence1': Value('string'), 'sentence2': Value('string'), 'label': ClassLabel(names=['not_equivalent', 'equivalent']), 'idx': Value('int32')}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "raw_datasets = load_dataset(\"glue\", task)\n",
    "\n",
    "print(f\"{raw_datasets}\\n\")\n",
    "print(f\"{raw_datasets[train_ds_name][0]}\\n\")\n",
    "print(f\"{raw_datasets[train_ds_name].features}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the following dictionaries when building our model with `AutoModelForSequenceClassification` to map between the label ids and names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label_maps(raw_datasets, train_ds_name):\n",
    "    labels = raw_datasets[train_ds_name].features[\"label\"]\n",
    "\n",
    "    id2label = {idx: name.upper() for idx, name in enumerate(labels.names)} if hasattr(labels, \"names\") else None\n",
    "    label2id = {name.upper(): idx for idx, name in enumerate(labels.names)} if hasattr(labels, \"names\") else None\n",
    "\n",
    "    return id2label, label2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'NOT_EQUIVALENT', 1: 'EQUIVALENT'}\n",
      "{'NOT_EQUIVALENT': 0, 'EQUIVALENT': 1}\n"
     ]
    }
   ],
   "source": [
    "id2label, label2id = get_label_maps(raw_datasets, train_ds_name)\n",
    "\n",
    "print(f\"{id2label}\")\n",
    "print(f\"{label2id}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MRPC is a sentence-pair classification task where we're given two sentences and asked to predict whether they are paraphrases of one another.  The dataset is split into train, validation and test sets. We'll need to keep all this in mind when we set up tokenization next with `AutoTokenizer`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizer\n",
    "\n",
    "Next we define our Tokenizer and a preprocess function to create the input_ids, attention_mask, and token_type_ids the model nees to train.  For this example, including `truncation=True` is enough as we'll rely on our data collation function below to put our batches into the correct shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sentence1', 'sentence2']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples, task_inputs):\n",
    "    inps = [examples[inp] for inp in task_inputs]\n",
    "    tokenized = hf_tokenizer(*inps, truncation=True)\n",
    "    return tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:   0%|          | 0/408 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 408/408 [00:00<00:00, 12356.59 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['sentence1', 'sentence2', 'label', 'idx', 'input_ids', 'attention_mask'],\n",
      "        num_rows: 3668\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['sentence1', 'sentence2', 'label', 'idx', 'input_ids', 'attention_mask'],\n",
      "        num_rows: 408\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['sentence1', 'sentence2', 'label', 'idx', 'input_ids', 'attention_mask'],\n",
      "        num_rows: 1725\n",
      "    })\n",
      "})\n",
      "\n",
      "{'sentence1': 'Amrozi accused his brother , whom he called \" the witness \" , of deliberately distorting his evidence .', 'sentence2': 'Referring to him as only \" the witness \" , Amrozi accused his brother of deliberately distorting his evidence .', 'label': 1, 'idx': 0, 'input_ids': [50281, 8096, 287, 9877, 10145, 521, 4929, 1157, 5207, 344, 1925, 346, 253, 5517, 346, 1157, 273, 21547, 940, 12655, 521, 1941, 964, 50282, 7676, 24247, 281, 779, 347, 760, 346, 253, 5517, 346, 1157, 3052, 287, 9877, 10145, 521, 4929, 273, 21547, 940, 12655, 521, 1941, 964, 50282], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
      "\n",
      "{'sentence1': Value('string'), 'sentence2': Value('string'), 'label': ClassLabel(names=['not_equivalent', 'equivalent']), 'idx': Value('int32'), 'input_ids': List(Value('int32')), 'attention_mask': List(Value('int8'))}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tokenized_datasets = raw_datasets.map(partial(preprocess_function, task_inputs=task_inputs), batched=True)\n",
    "\n",
    "print(f\"{tokenized_datasets}\\n\")\n",
    "print(f\"{tokenized_datasets[train_ds_name][0]}\\n\")\n",
    "print(f\"{tokenized_datasets[train_ds_name].features}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's always good to see what the tokenizer is doing to our data to ensure the special tokens are where we expect them to be!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS]Amrozi accused his brother, whom he called \" the witness \", of deliberately distorting his evidence.[SEP]Referring to him as only \" the witness \", Amrozi accused his brother of deliberately distorting his evidence.[SEP]'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf_tokenizer.decode(tokenized_datasets[train_ds_name][0][\"input_ids\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use our `task_metrics` to compute the metrics for our model.  We'll return a dictionary of the metric name and value for each metric we're interested in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred, task_metrics):\n",
    "    predictions, labels = eval_pred\n",
    "\n",
    "    metrics_d = {}\n",
    "    for metric_func in task_metrics:\n",
    "        metric_name = metric_func.__name__\n",
    "        if metric_name in [\"pearsonr\", \"spearmanr\"]:\n",
    "            score = metric_func(labels, np.squeeze(predictions))\n",
    "        else:\n",
    "            score = metric_func(np.argmax(predictions, axis=-1), labels)\n",
    "\n",
    "        if isinstance(score, tuple):\n",
    "            metrics_d[metric_func.__name__] = score[0]\n",
    "        else:\n",
    "            metrics_d[metric_func.__name__] = score\n",
    "\n",
    "    return metrics_d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train\n",
    "\n",
    "This is where the fun begins! Here we setup a few hyperparameters than have proven to work well for us in fine-tuning ModernBERT-base on GLUE tasks.  We'll also setup our model, data collator, and training arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_bsz, val_bsz = 32, 32\n",
    "lr = 8e-5\n",
    "betas = (0.9, 0.98)\n",
    "n_epochs = 2\n",
    "eps = 1e-6\n",
    "wd = 8e-6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When configuring `AutoModelForSequenceClassification`, two settings are critical to get things working with the HuggingFace `Trainer`. One is the `num_labels` we're expecting and the other is to set `compile=False` to avoid using the `torch.compile` function which is not supported in Transformers at the time of this writing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in ModernBertForSequenceClassification is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained(\"openai/whisper-tiny\", attn_implementation=\"flash_attention_2\", dtype=torch.float16)`\n",
      "Flash Attention 2 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in ModernBertModel is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `dtype` argument. Example: `model = AutoModel.from_pretrained(\"openai/whisper-tiny\", attn_implementation=\"flash_attention_2\", dtype=torch.float16)`\n",
      "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at output_model/modernbert-diffusion-1b and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "hf_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    checkpoint, num_labels=n_labels, id2label=id2label, label2id=label2id\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collation is easy for GLUE tasks as we can use the `DataCollatorWithPadding` class to pad our input_ids and attention_mask to the max length in the batch.\n",
    "\n",
    "**Note**: If you have installed Flash Attention, ModernBERT removes the padding internally, which makes it the fastest version. SPDA and Eager mode will be slower."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_data_collator = DataCollatorWithPadding(tokenizer=hf_tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With all the pieces in place, we can now setup our `TrainingArguments` and `Trainer` and get to training! Lots of customization is possible here and it is recommended to play with different schedulers and the hyperparameters we've started y'all off with above to improve results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=f\"aai_ModernBERT_{task}_ft\",\n",
    "    learning_rate=lr,\n",
    "    per_device_train_batch_size=train_bsz,\n",
    "    per_device_eval_batch_size=val_bsz,\n",
    "    num_train_epochs=n_epochs,\n",
    "    lr_scheduler_type=\"linear\",\n",
    "    optim=\"adamw_torch\",\n",
    "    adam_beta1=betas[0],\n",
    "    adam_beta2=betas[1],\n",
    "    adam_epsilon=eps,\n",
    "    logging_strategy=\"epoch\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    bf16=True,\n",
    "    bf16_full_eval=True,\n",
    "    push_to_hub=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define `TrainerCallback` so that we can capture all the training and evaluation logs and store them for later analysis. By default, the `Trainer` class will only keep the latest logs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetricsCallback(TrainerCallback):\n",
    "    def __init__(self):\n",
    "        self.training_history = {\"train\": [], \"eval\": []}\n",
    "\n",
    "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
    "        if logs is not None:\n",
    "            if \"loss\" in logs:  # Training logs\n",
    "                self.training_history[\"train\"].append(logs)\n",
    "            elif \"eval_loss\" in logs:  # Evaluation logs\n",
    "                self.training_history[\"eval\"].append(logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'eos_token_id': None, 'bos_token_id': None}.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='230' max='230' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [230/230 00:03, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy Score</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.728300</td>\n",
       "      <td>0.599436</td>\n",
       "      <td>0.718137</td>\n",
       "      <td>0.821151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.514600</td>\n",
       "      <td>0.588149</td>\n",
       "      <td>0.715686</td>\n",
       "      <td>0.813505</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_grad_norm</th>\n",
       "      <th>train_learning_rate</th>\n",
       "      <th>train_epoch</th>\n",
       "      <th>eval_loss</th>\n",
       "      <th>eval_accuracy_score</th>\n",
       "      <th>eval_f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.7283</td>\n",
       "      <td>4.591911</td>\n",
       "      <td>4.034783e-05</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.599436</td>\n",
       "      <td>0.718137</td>\n",
       "      <td>0.821151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.5146</td>\n",
       "      <td>3.610186</td>\n",
       "      <td>3.478261e-07</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.588149</td>\n",
       "      <td>0.715686</td>\n",
       "      <td>0.813505</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_loss  train_grad_norm  train_learning_rate  train_epoch  eval_loss  \\\n",
       "0      0.7283         4.591911         4.034783e-05          1.0   0.599436   \n",
       "1      0.5146         3.610186         3.478261e-07          2.0   0.588149   \n",
       "\n",
       "   eval_accuracy_score  eval_f1_score  \n",
       "0             0.718137       0.821151  \n",
       "1             0.715686       0.813505  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>output_dir</th>\n",
       "      <th>overwrite_output_dir</th>\n",
       "      <th>do_train</th>\n",
       "      <th>do_eval</th>\n",
       "      <th>do_predict</th>\n",
       "      <th>eval_strategy</th>\n",
       "      <th>prediction_loss_only</th>\n",
       "      <th>per_device_train_batch_size</th>\n",
       "      <th>per_device_eval_batch_size</th>\n",
       "      <th>per_gpu_train_batch_size</th>\n",
       "      <th>...</th>\n",
       "      <th>include_tokens_per_second</th>\n",
       "      <th>include_num_input_tokens_seen</th>\n",
       "      <th>neftune_noise_alpha</th>\n",
       "      <th>optim_target_modules</th>\n",
       "      <th>batch_eval_metrics</th>\n",
       "      <th>eval_on_start</th>\n",
       "      <th>use_liger_kernel</th>\n",
       "      <th>liger_kernel_config</th>\n",
       "      <th>eval_use_gather_object</th>\n",
       "      <th>average_tokens_across_devices</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aai_ModernBERT_mrpc_ft</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>epoch</td>\n",
       "      <td>False</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 131 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               output_dir  overwrite_output_dir  do_train  do_eval  \\\n",
       "0  aai_ModernBERT_mrpc_ft                 False     False     True   \n",
       "\n",
       "   do_predict eval_strategy  prediction_loss_only  \\\n",
       "0       False         epoch                 False   \n",
       "\n",
       "   per_device_train_batch_size  per_device_eval_batch_size  \\\n",
       "0                           32                          32   \n",
       "\n",
       "  per_gpu_train_batch_size  ... include_tokens_per_second  \\\n",
       "0                     None  ...                     False   \n",
       "\n",
       "   include_num_input_tokens_seen neftune_noise_alpha  optim_target_modules  \\\n",
       "0                          False                None                  None   \n",
       "\n",
       "  batch_eval_metrics  eval_on_start  use_liger_kernel  liger_kernel_config  \\\n",
       "0              False          False             False                 None   \n",
       "\n",
       "   eval_use_gather_object  average_tokens_across_devices  \n",
       "0                   False                          False  \n",
       "\n",
       "[1 rows x 131 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=hf_model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[train_ds_name],\n",
    "    eval_dataset=tokenized_datasets[valid_ds_name],\n",
    "    processing_class=hf_tokenizer,\n",
    "    data_collator=hf_data_collator,\n",
    "    compute_metrics=partial(compute_metrics, task_metrics=task_metrics),\n",
    ")\n",
    "\n",
    "metrics_callback = MetricsCallback()\n",
    "trainer.add_callback(metrics_callback)\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "train_history_df = pd.DataFrame(metrics_callback.training_history[\"train\"])\n",
    "train_history_df = train_history_df.add_prefix(\"train_\")\n",
    "eval_history_df = pd.DataFrame(metrics_callback.training_history[\"eval\"])\n",
    "train_res_df = pd.concat([train_history_df, eval_history_df], axis=1)\n",
    "\n",
    "args_df = pd.DataFrame([training_args.to_dict()])\n",
    "\n",
    "display(train_res_df)\n",
    "display(args_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference\n",
    "\n",
    "There'a number of options for inference within the HuggingFace ecosystem.  We'll go a bit old school here and just use the `forward` method of the model. We're not uploading this model to the hub, but this is an easy enough task for you to try out on your own should you like to share your ModernBERT finetune :)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.1406, -1.3672]], device='cuda:0')\n",
      "Prediction: NOT_EQUIVALENT\n"
     ]
    }
   ],
   "source": [
    "ex_1 = \"The quick brown fox jumps over the lazy dog.\"\n",
    "ex_2 = \"I love lamp!\"\n",
    "\n",
    "inf_inputs = hf_tokenizer(ex_1, ex_2, return_tensors=\"pt\")\n",
    "inf_inputs = inf_inputs.to(\"cuda\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    logits = hf_model(**inf_inputs).logits\n",
    "\n",
    "print(logits)\n",
    "print(f\"Prediction: {hf_model.config.id2label[logits.argmax().item()]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanup(things_to_delete: list | None = None):\n",
    "    if things_to_delete is not None:\n",
    "        for thing in things_to_delete:\n",
    "            if thing is not None:\n",
    "                del thing\n",
    "\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanup(things_to_delete=[hf_model, trainer])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train all the GLUE!\n",
    "\n",
    "If you got this far you're probably wondering why I put together that dictionary of GLUE tasks if all we're doing is finetuning a single model. The answer is basically that I'm a good and lazy programmer who would like to easily run hyperparameter sweeps and/or fine-tunes on all the GLUE tasks. So ... let's do that!\n",
    "\n",
    "We'll run with the training hyperparameters specified above and I leave it to the reader to improve the method below to be able to override these values should folks be looking for something to do :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def finetune_glue_task(\n",
    "    task: str, checkpoint: str = \"answerdotai/ModernBERT-base\", train_subset: int | None = None, do_cleanup: bool = True\n",
    "):  # 1. Load the task metadata\n",
    "    task_meta = glue_tasks[task]\n",
    "    train_ds_name = task_meta[\"dataset_names\"][\"train\"]\n",
    "    valid_ds_name = task_meta[\"dataset_names\"][\"valid\"]\n",
    "\n",
    "    task_inputs = task_meta[\"inputs\"]\n",
    "    n_labels = task_meta[\"n_labels\"]\n",
    "    task_metrics = task_meta[\"metric_funcs\"]\n",
    "\n",
    "    # 2. Load the dataset\n",
    "    raw_datasets = load_dataset(\"glue\", task.split(\"-\")[0] if \"-\" in task else task)\n",
    "    if train_subset is not None and len(raw_datasets[\"train\"]) > train_subset:\n",
    "        raw_datasets[\"train\"] = raw_datasets[\"train\"].shuffle(seed=42).select(range(train_subset))\n",
    "\n",
    "    id2label, label2id = get_label_maps(raw_datasets, train_ds_name)\n",
    "\n",
    "    # 3. Load the tokenizer\n",
    "    hf_tokenizer = AutoTokenizer.from_pretrained(\"answerdotai/ModernBERT-base\")\n",
    "    tokenized_datasets = raw_datasets.map(partial(preprocess_function, task_inputs=task_inputs), batched=True)\n",
    "\n",
    "    # 4. Define the compute metrics function\n",
    "    task_compute_metrics = partial(compute_metrics, task_metrics=task_metrics)\n",
    "\n",
    "    # 5. Load the model and data collator\n",
    "    model_additional_kwargs = {\"id2label\": id2label, \"label2id\": label2id} if id2label and label2id else {}\n",
    "    hf_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        checkpoint, num_labels=n_labels, **model_additional_kwargs\n",
    "    )\n",
    "\n",
    "    hf_data_collator = DataCollatorWithPadding(tokenizer=hf_tokenizer)\n",
    "\n",
    "    # 6. Define the training arguments and trainer\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=f\"aai_ModernBERT_{task}_ft\",\n",
    "        learning_rate=lr,\n",
    "        per_device_train_batch_size=train_bsz,\n",
    "        per_device_eval_batch_size=val_bsz,\n",
    "        num_train_epochs=n_epochs,\n",
    "        lr_scheduler_type=\"linear\",\n",
    "        optim=\"adamw_torch\",\n",
    "        adam_beta1=betas[0],\n",
    "        adam_beta2=betas[1],\n",
    "        adam_epsilon=eps,\n",
    "        logging_strategy=\"epoch\",\n",
    "        eval_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        load_best_model_at_end=True,\n",
    "        bf16=True,\n",
    "        bf16_full_eval=True,\n",
    "        push_to_hub=False,\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=hf_model,\n",
    "        args=training_args,\n",
    "        train_dataset=tokenized_datasets[train_ds_name],\n",
    "        eval_dataset=tokenized_datasets[valid_ds_name],\n",
    "        processing_class=hf_tokenizer,\n",
    "        data_collator=hf_data_collator,\n",
    "        compute_metrics=task_compute_metrics,\n",
    "    )\n",
    "\n",
    "    # Add callback to trainer\n",
    "    metrics_callback = MetricsCallback()\n",
    "    trainer.add_callback(metrics_callback)\n",
    "\n",
    "    trainer.train()\n",
    "\n",
    "    # 7. Get the training results and hyperparameters\n",
    "    train_history_df = pd.DataFrame(metrics_callback.training_history[\"train\"])\n",
    "    train_history_df = train_history_df.add_prefix(\"train_\")\n",
    "    eval_history_df = pd.DataFrame(metrics_callback.training_history[\"eval\"])\n",
    "    train_res_df = pd.concat([train_history_df, eval_history_df], axis=1)\n",
    "\n",
    "    args_df = pd.DataFrame([training_args.to_dict()])\n",
    "\n",
    "    # 8. Cleanup (optional)\n",
    "    if do_cleanup:\n",
    "        cleanup(things_to_delete=[trainer, hf_model, hf_tokenizer, tokenized_datasets, raw_datasets])\n",
    "\n",
    "    return train_res_df, args_df, hf_model, hf_tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This helpful function encapsulates all the steps we've been through above and allows us to easily run a fine-tune on a single task. In addition to the HuggingFace objects, it returns the training results, training hyperparameters (all potentially helpful for performing sweeps and or documenting your results).\n",
    "\n",
    "Let's give it a go on both MRPC and CoLA.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 3668/3668 [00:00<00:00, 13951.57 examples/s]\n",
      "Map: 100%|██████████| 408/408 [00:00<00:00, 13413.67 examples/s]\n",
      "Map: 100%|██████████| 1725/1725 [00:00<00:00, 14059.15 examples/s]\n",
      "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at output_model/modernbert-diffusion-1b and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'eos_token_id': None, 'bos_token_id': None}.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='230' max='230' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [230/230 00:03, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy Score</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.724300</td>\n",
       "      <td>0.569719</td>\n",
       "      <td>0.730392</td>\n",
       "      <td>0.832827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.508100</td>\n",
       "      <td>0.557317</td>\n",
       "      <td>0.740196</td>\n",
       "      <td>0.833856</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_grad_norm</th>\n",
       "      <th>train_learning_rate</th>\n",
       "      <th>train_epoch</th>\n",
       "      <th>eval_loss</th>\n",
       "      <th>eval_accuracy_score</th>\n",
       "      <th>eval_f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.7243</td>\n",
       "      <td>3.341632</td>\n",
       "      <td>4.034783e-05</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.569719</td>\n",
       "      <td>0.730392</td>\n",
       "      <td>0.832827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.5081</td>\n",
       "      <td>4.132639</td>\n",
       "      <td>3.478261e-07</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.557317</td>\n",
       "      <td>0.740196</td>\n",
       "      <td>0.833856</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_loss  train_grad_norm  train_learning_rate  train_epoch  eval_loss  \\\n",
       "0      0.7243         3.341632         4.034783e-05          1.0   0.569719   \n",
       "1      0.5081         4.132639         3.478261e-07          2.0   0.557317   \n",
       "\n",
       "   eval_accuracy_score  eval_f1_score  \n",
       "0             0.730392       0.832827  \n",
       "1             0.740196       0.833856  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>output_dir</th>\n",
       "      <th>overwrite_output_dir</th>\n",
       "      <th>do_train</th>\n",
       "      <th>do_eval</th>\n",
       "      <th>do_predict</th>\n",
       "      <th>eval_strategy</th>\n",
       "      <th>prediction_loss_only</th>\n",
       "      <th>per_device_train_batch_size</th>\n",
       "      <th>per_device_eval_batch_size</th>\n",
       "      <th>per_gpu_train_batch_size</th>\n",
       "      <th>...</th>\n",
       "      <th>include_tokens_per_second</th>\n",
       "      <th>include_num_input_tokens_seen</th>\n",
       "      <th>neftune_noise_alpha</th>\n",
       "      <th>optim_target_modules</th>\n",
       "      <th>batch_eval_metrics</th>\n",
       "      <th>eval_on_start</th>\n",
       "      <th>use_liger_kernel</th>\n",
       "      <th>liger_kernel_config</th>\n",
       "      <th>eval_use_gather_object</th>\n",
       "      <th>average_tokens_across_devices</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aai_ModernBERT_mrpc_ft</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>epoch</td>\n",
       "      <td>False</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 131 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               output_dir  overwrite_output_dir  do_train  do_eval  \\\n",
       "0  aai_ModernBERT_mrpc_ft                 False     False     True   \n",
       "\n",
       "   do_predict eval_strategy  prediction_loss_only  \\\n",
       "0       False         epoch                 False   \n",
       "\n",
       "   per_device_train_batch_size  per_device_eval_batch_size  \\\n",
       "0                           32                          32   \n",
       "\n",
       "  per_gpu_train_batch_size  ... include_tokens_per_second  \\\n",
       "0                     None  ...                     False   \n",
       "\n",
       "   include_num_input_tokens_seen neftune_noise_alpha  optim_target_modules  \\\n",
       "0                          False                None                  None   \n",
       "\n",
       "  batch_eval_metrics  eval_on_start  use_liger_kernel  liger_kernel_config  \\\n",
       "0              False          False             False                 None   \n",
       "\n",
       "   eval_use_gather_object  average_tokens_across_devices  \n",
       "0                   False                          False  \n",
       "\n",
       "[1 rows x 131 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_res_df, args_df, hf_model, hf_tokenizer = finetune_glue_task(\n",
    "    \"mrpc\", checkpoint=checkpoint, do_cleanup=True\n",
    ")\n",
    "\n",
    "display(train_res_df)\n",
    "display(args_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at output_model/modernbert-diffusion-1b and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'eos_token_id': None, 'bos_token_id': None}.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='536' max='536' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [536/536 00:06, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Matthews Corrcoef</th>\n",
       "      <th>Accuracy Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.640100</td>\n",
       "      <td>0.599142</td>\n",
       "      <td>0.098772</td>\n",
       "      <td>0.690316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.510400</td>\n",
       "      <td>0.607198</td>\n",
       "      <td>0.123063</td>\n",
       "      <td>0.689358</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_grad_norm</th>\n",
       "      <th>train_learning_rate</th>\n",
       "      <th>train_epoch</th>\n",
       "      <th>eval_loss</th>\n",
       "      <th>eval_matthews_corrcoef</th>\n",
       "      <th>eval_accuracy_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.6401</td>\n",
       "      <td>3.880660</td>\n",
       "      <td>4.014925e-05</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.599142</td>\n",
       "      <td>0.098772</td>\n",
       "      <td>0.690316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.5104</td>\n",
       "      <td>4.748318</td>\n",
       "      <td>1.492537e-07</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.607198</td>\n",
       "      <td>0.123063</td>\n",
       "      <td>0.689358</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_loss  train_grad_norm  train_learning_rate  train_epoch  eval_loss  \\\n",
       "0      0.6401         3.880660         4.014925e-05          1.0   0.599142   \n",
       "1      0.5104         4.748318         1.492537e-07          2.0   0.607198   \n",
       "\n",
       "   eval_matthews_corrcoef  eval_accuracy_score  \n",
       "0                0.098772             0.690316  \n",
       "1                0.123063             0.689358  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>output_dir</th>\n",
       "      <th>overwrite_output_dir</th>\n",
       "      <th>do_train</th>\n",
       "      <th>do_eval</th>\n",
       "      <th>do_predict</th>\n",
       "      <th>eval_strategy</th>\n",
       "      <th>prediction_loss_only</th>\n",
       "      <th>per_device_train_batch_size</th>\n",
       "      <th>per_device_eval_batch_size</th>\n",
       "      <th>per_gpu_train_batch_size</th>\n",
       "      <th>...</th>\n",
       "      <th>include_tokens_per_second</th>\n",
       "      <th>include_num_input_tokens_seen</th>\n",
       "      <th>neftune_noise_alpha</th>\n",
       "      <th>optim_target_modules</th>\n",
       "      <th>batch_eval_metrics</th>\n",
       "      <th>eval_on_start</th>\n",
       "      <th>use_liger_kernel</th>\n",
       "      <th>liger_kernel_config</th>\n",
       "      <th>eval_use_gather_object</th>\n",
       "      <th>average_tokens_across_devices</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aai_ModernBERT_cola_ft</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>epoch</td>\n",
       "      <td>False</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 131 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               output_dir  overwrite_output_dir  do_train  do_eval  \\\n",
       "0  aai_ModernBERT_cola_ft                 False     False     True   \n",
       "\n",
       "   do_predict eval_strategy  prediction_loss_only  \\\n",
       "0       False         epoch                 False   \n",
       "\n",
       "   per_device_train_batch_size  per_device_eval_batch_size  \\\n",
       "0                           32                          32   \n",
       "\n",
       "  per_gpu_train_batch_size  ... include_tokens_per_second  \\\n",
       "0                     None  ...                     False   \n",
       "\n",
       "   include_num_input_tokens_seen neftune_noise_alpha  optim_target_modules  \\\n",
       "0                          False                None                  None   \n",
       "\n",
       "  batch_eval_metrics  eval_on_start  use_liger_kernel  liger_kernel_config  \\\n",
       "0              False          False             False                 None   \n",
       "\n",
       "   eval_use_gather_object  average_tokens_across_devices  \n",
       "0                   False                          False  \n",
       "\n",
       "[1 rows x 131 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_res_df, args_df, hf_model, hf_tokenizer = finetune_glue_task(\n",
    "    \"cola\", checkpoint=checkpoint, do_cleanup=True\n",
    ")\n",
    "\n",
    "display(train_res_df)\n",
    "display(args_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Send it!**\n",
    "\n",
    "Grab yourself a good cup of coffee, take your pups out for a walk, or whatever as your GPU purrs along while finetuning all things GLUE!\n",
    "\n",
    "Note the `train_subset` parameter which allows us to train on a subset of the dataset. This is helpful for quickly testing the model on a small dataset to make sure all the bits work as expected.  Feel free to set it to `None` for a full send!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Finetuning cola -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at output_model/modernbert-diffusion-1b and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'eos_token_id': None, 'bos_token_id': None}.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='536' max='536' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [536/536 00:06, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Matthews Corrcoef</th>\n",
       "      <th>Accuracy Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.640200</td>\n",
       "      <td>0.599160</td>\n",
       "      <td>0.109335</td>\n",
       "      <td>0.692234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.510500</td>\n",
       "      <td>0.606568</td>\n",
       "      <td>0.120251</td>\n",
       "      <td>0.688399</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: Results ::\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_grad_norm</th>\n",
       "      <th>train_learning_rate</th>\n",
       "      <th>train_epoch</th>\n",
       "      <th>eval_loss</th>\n",
       "      <th>eval_matthews_corrcoef</th>\n",
       "      <th>eval_accuracy_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.6402</td>\n",
       "      <td>3.848574</td>\n",
       "      <td>4.014925e-05</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.599160</td>\n",
       "      <td>0.109335</td>\n",
       "      <td>0.692234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.5105</td>\n",
       "      <td>4.709330</td>\n",
       "      <td>1.492537e-07</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.606568</td>\n",
       "      <td>0.120251</td>\n",
       "      <td>0.688399</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_loss  train_grad_norm  train_learning_rate  train_epoch  eval_loss  \\\n",
       "0      0.6402         3.848574         4.014925e-05          1.0   0.599160   \n",
       "1      0.5105         4.709330         1.492537e-07          2.0   0.606568   \n",
       "\n",
       "   eval_matthews_corrcoef  eval_accuracy_score  \n",
       "0                0.109335             0.692234  \n",
       "1                0.120251             0.688399  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>output_dir</th>\n",
       "      <th>overwrite_output_dir</th>\n",
       "      <th>do_train</th>\n",
       "      <th>do_eval</th>\n",
       "      <th>do_predict</th>\n",
       "      <th>eval_strategy</th>\n",
       "      <th>prediction_loss_only</th>\n",
       "      <th>per_device_train_batch_size</th>\n",
       "      <th>per_device_eval_batch_size</th>\n",
       "      <th>per_gpu_train_batch_size</th>\n",
       "      <th>...</th>\n",
       "      <th>include_tokens_per_second</th>\n",
       "      <th>include_num_input_tokens_seen</th>\n",
       "      <th>neftune_noise_alpha</th>\n",
       "      <th>optim_target_modules</th>\n",
       "      <th>batch_eval_metrics</th>\n",
       "      <th>eval_on_start</th>\n",
       "      <th>use_liger_kernel</th>\n",
       "      <th>liger_kernel_config</th>\n",
       "      <th>eval_use_gather_object</th>\n",
       "      <th>average_tokens_across_devices</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aai_ModernBERT_cola_ft</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>epoch</td>\n",
       "      <td>False</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 131 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               output_dir  overwrite_output_dir  do_train  do_eval  \\\n",
       "0  aai_ModernBERT_cola_ft                 False     False     True   \n",
       "\n",
       "   do_predict eval_strategy  prediction_loss_only  \\\n",
       "0       False         epoch                 False   \n",
       "\n",
       "   per_device_train_batch_size  per_device_eval_batch_size  \\\n",
       "0                           32                          32   \n",
       "\n",
       "  per_gpu_train_batch_size  ... include_tokens_per_second  \\\n",
       "0                     None  ...                     False   \n",
       "\n",
       "   include_num_input_tokens_seen neftune_noise_alpha  optim_target_modules  \\\n",
       "0                          False                None                  None   \n",
       "\n",
       "  batch_eval_metrics  eval_on_start  use_liger_kernel  liger_kernel_config  \\\n",
       "0              False          False             False                 None   \n",
       "\n",
       "   eval_use_gather_object  average_tokens_across_devices  \n",
       "0                   False                          False  \n",
       "\n",
       "[1 rows x 131 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Finetuning sst2 -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at output_model/modernbert-diffusion-1b and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'eos_token_id': None, 'bos_token_id': None}.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4210' max='4210' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4210/4210 00:45, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.369100</td>\n",
       "      <td>0.401960</td>\n",
       "      <td>0.832569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.178600</td>\n",
       "      <td>0.459990</td>\n",
       "      <td>0.833716</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: Results ::\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_grad_norm</th>\n",
       "      <th>train_learning_rate</th>\n",
       "      <th>train_epoch</th>\n",
       "      <th>eval_loss</th>\n",
       "      <th>eval_accuracy_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.3691</td>\n",
       "      <td>2.681734</td>\n",
       "      <td>4.001900e-05</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.40196</td>\n",
       "      <td>0.832569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.1786</td>\n",
       "      <td>2.931861</td>\n",
       "      <td>1.900238e-08</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.45999</td>\n",
       "      <td>0.833716</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_loss  train_grad_norm  train_learning_rate  train_epoch  eval_loss  \\\n",
       "0      0.3691         2.681734         4.001900e-05          1.0    0.40196   \n",
       "1      0.1786         2.931861         1.900238e-08          2.0    0.45999   \n",
       "\n",
       "   eval_accuracy_score  \n",
       "0             0.832569  \n",
       "1             0.833716  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>output_dir</th>\n",
       "      <th>overwrite_output_dir</th>\n",
       "      <th>do_train</th>\n",
       "      <th>do_eval</th>\n",
       "      <th>do_predict</th>\n",
       "      <th>eval_strategy</th>\n",
       "      <th>prediction_loss_only</th>\n",
       "      <th>per_device_train_batch_size</th>\n",
       "      <th>per_device_eval_batch_size</th>\n",
       "      <th>per_gpu_train_batch_size</th>\n",
       "      <th>...</th>\n",
       "      <th>include_tokens_per_second</th>\n",
       "      <th>include_num_input_tokens_seen</th>\n",
       "      <th>neftune_noise_alpha</th>\n",
       "      <th>optim_target_modules</th>\n",
       "      <th>batch_eval_metrics</th>\n",
       "      <th>eval_on_start</th>\n",
       "      <th>use_liger_kernel</th>\n",
       "      <th>liger_kernel_config</th>\n",
       "      <th>eval_use_gather_object</th>\n",
       "      <th>average_tokens_across_devices</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aai_ModernBERT_sst2_ft</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>epoch</td>\n",
       "      <td>False</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 131 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               output_dir  overwrite_output_dir  do_train  do_eval  \\\n",
       "0  aai_ModernBERT_sst2_ft                 False     False     True   \n",
       "\n",
       "   do_predict eval_strategy  prediction_loss_only  \\\n",
       "0       False         epoch                 False   \n",
       "\n",
       "   per_device_train_batch_size  per_device_eval_batch_size  \\\n",
       "0                           32                          32   \n",
       "\n",
       "  per_gpu_train_batch_size  ... include_tokens_per_second  \\\n",
       "0                     None  ...                     False   \n",
       "\n",
       "   include_num_input_tokens_seen neftune_noise_alpha  optim_target_modules  \\\n",
       "0                          False                None                  None   \n",
       "\n",
       "  batch_eval_metrics  eval_on_start  use_liger_kernel  liger_kernel_config  \\\n",
       "0              False          False             False                 None   \n",
       "\n",
       "   eval_use_gather_object  average_tokens_across_devices  \n",
       "0                   False                          False  \n",
       "\n",
       "[1 rows x 131 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Finetuning mrpc -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at output_model/modernbert-diffusion-1b and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'eos_token_id': None, 'bos_token_id': None}.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='230' max='230' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [230/230 00:03, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy Score</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.724200</td>\n",
       "      <td>0.569723</td>\n",
       "      <td>0.727941</td>\n",
       "      <td>0.831050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.508100</td>\n",
       "      <td>0.557451</td>\n",
       "      <td>0.740196</td>\n",
       "      <td>0.833856</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: Results ::\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_grad_norm</th>\n",
       "      <th>train_learning_rate</th>\n",
       "      <th>train_epoch</th>\n",
       "      <th>eval_loss</th>\n",
       "      <th>eval_accuracy_score</th>\n",
       "      <th>eval_f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.7242</td>\n",
       "      <td>3.333426</td>\n",
       "      <td>4.034783e-05</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.569723</td>\n",
       "      <td>0.727941</td>\n",
       "      <td>0.831050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.5081</td>\n",
       "      <td>4.196676</td>\n",
       "      <td>3.478261e-07</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.557451</td>\n",
       "      <td>0.740196</td>\n",
       "      <td>0.833856</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_loss  train_grad_norm  train_learning_rate  train_epoch  eval_loss  \\\n",
       "0      0.7242         3.333426         4.034783e-05          1.0   0.569723   \n",
       "1      0.5081         4.196676         3.478261e-07          2.0   0.557451   \n",
       "\n",
       "   eval_accuracy_score  eval_f1_score  \n",
       "0             0.727941       0.831050  \n",
       "1             0.740196       0.833856  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>output_dir</th>\n",
       "      <th>overwrite_output_dir</th>\n",
       "      <th>do_train</th>\n",
       "      <th>do_eval</th>\n",
       "      <th>do_predict</th>\n",
       "      <th>eval_strategy</th>\n",
       "      <th>prediction_loss_only</th>\n",
       "      <th>per_device_train_batch_size</th>\n",
       "      <th>per_device_eval_batch_size</th>\n",
       "      <th>per_gpu_train_batch_size</th>\n",
       "      <th>...</th>\n",
       "      <th>include_tokens_per_second</th>\n",
       "      <th>include_num_input_tokens_seen</th>\n",
       "      <th>neftune_noise_alpha</th>\n",
       "      <th>optim_target_modules</th>\n",
       "      <th>batch_eval_metrics</th>\n",
       "      <th>eval_on_start</th>\n",
       "      <th>use_liger_kernel</th>\n",
       "      <th>liger_kernel_config</th>\n",
       "      <th>eval_use_gather_object</th>\n",
       "      <th>average_tokens_across_devices</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aai_ModernBERT_mrpc_ft</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>epoch</td>\n",
       "      <td>False</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 131 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               output_dir  overwrite_output_dir  do_train  do_eval  \\\n",
       "0  aai_ModernBERT_mrpc_ft                 False     False     True   \n",
       "\n",
       "   do_predict eval_strategy  prediction_loss_only  \\\n",
       "0       False         epoch                 False   \n",
       "\n",
       "   per_device_train_batch_size  per_device_eval_batch_size  \\\n",
       "0                           32                          32   \n",
       "\n",
       "  per_gpu_train_batch_size  ... include_tokens_per_second  \\\n",
       "0                     None  ...                     False   \n",
       "\n",
       "   include_num_input_tokens_seen neftune_noise_alpha  optim_target_modules  \\\n",
       "0                          False                None                  None   \n",
       "\n",
       "  batch_eval_metrics  eval_on_start  use_liger_kernel  liger_kernel_config  \\\n",
       "0              False          False             False                 None   \n",
       "\n",
       "   eval_use_gather_object  average_tokens_across_devices  \n",
       "0                   False                          False  \n",
       "\n",
       "[1 rows x 131 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Finetuning stsb -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at output_model/modernbert-diffusion-1b and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'eos_token_id': None, 'bos_token_id': None}.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='360' max='360' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [360/360 00:04, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Pearsonr</th>\n",
       "      <th>Spearmanr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.734600</td>\n",
       "      <td>1.888843</td>\n",
       "      <td>0.504394</td>\n",
       "      <td>0.501757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.377100</td>\n",
       "      <td>1.676585</td>\n",
       "      <td>0.529895</td>\n",
       "      <td>0.523065</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: Results ::\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_grad_norm</th>\n",
       "      <th>train_learning_rate</th>\n",
       "      <th>train_epoch</th>\n",
       "      <th>eval_loss</th>\n",
       "      <th>eval_pearsonr</th>\n",
       "      <th>eval_spearmanr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.7346</td>\n",
       "      <td>35.054741</td>\n",
       "      <td>4.022222e-05</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.888843</td>\n",
       "      <td>0.504394</td>\n",
       "      <td>0.501757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.3771</td>\n",
       "      <td>17.149046</td>\n",
       "      <td>2.222222e-07</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.676585</td>\n",
       "      <td>0.529895</td>\n",
       "      <td>0.523065</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_loss  train_grad_norm  train_learning_rate  train_epoch  eval_loss  \\\n",
       "0      2.7346        35.054741         4.022222e-05          1.0   1.888843   \n",
       "1      1.3771        17.149046         2.222222e-07          2.0   1.676585   \n",
       "\n",
       "   eval_pearsonr  eval_spearmanr  \n",
       "0       0.504394        0.501757  \n",
       "1       0.529895        0.523065  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>output_dir</th>\n",
       "      <th>overwrite_output_dir</th>\n",
       "      <th>do_train</th>\n",
       "      <th>do_eval</th>\n",
       "      <th>do_predict</th>\n",
       "      <th>eval_strategy</th>\n",
       "      <th>prediction_loss_only</th>\n",
       "      <th>per_device_train_batch_size</th>\n",
       "      <th>per_device_eval_batch_size</th>\n",
       "      <th>per_gpu_train_batch_size</th>\n",
       "      <th>...</th>\n",
       "      <th>include_tokens_per_second</th>\n",
       "      <th>include_num_input_tokens_seen</th>\n",
       "      <th>neftune_noise_alpha</th>\n",
       "      <th>optim_target_modules</th>\n",
       "      <th>batch_eval_metrics</th>\n",
       "      <th>eval_on_start</th>\n",
       "      <th>use_liger_kernel</th>\n",
       "      <th>liger_kernel_config</th>\n",
       "      <th>eval_use_gather_object</th>\n",
       "      <th>average_tokens_across_devices</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aai_ModernBERT_stsb_ft</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>epoch</td>\n",
       "      <td>False</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 131 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               output_dir  overwrite_output_dir  do_train  do_eval  \\\n",
       "0  aai_ModernBERT_stsb_ft                 False     False     True   \n",
       "\n",
       "   do_predict eval_strategy  prediction_loss_only  \\\n",
       "0       False         epoch                 False   \n",
       "\n",
       "   per_device_train_batch_size  per_device_eval_batch_size  \\\n",
       "0                           32                          32   \n",
       "\n",
       "  per_gpu_train_batch_size  ... include_tokens_per_second  \\\n",
       "0                     None  ...                     False   \n",
       "\n",
       "   include_num_input_tokens_seen neftune_noise_alpha  optim_target_modules  \\\n",
       "0                          False                None                  None   \n",
       "\n",
       "  batch_eval_metrics  eval_on_start  use_liger_kernel  liger_kernel_config  \\\n",
       "0              False          False             False                 None   \n",
       "\n",
       "   eval_use_gather_object  average_tokens_across_devices  \n",
       "0                   False                          False  \n",
       "\n",
       "[1 rows x 131 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Finetuning qqp -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at output_model/modernbert-diffusion-1b and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'eos_token_id': None, 'bos_token_id': None}.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='22742' max='22742' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [22742/22742 04:15, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Accuracy Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.396100</td>\n",
       "      <td>0.344694</td>\n",
       "      <td>0.789399</td>\n",
       "      <td>0.842172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.268700</td>\n",
       "      <td>0.331557</td>\n",
       "      <td>0.803835</td>\n",
       "      <td>0.854242</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: Results ::\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_grad_norm</th>\n",
       "      <th>train_learning_rate</th>\n",
       "      <th>train_epoch</th>\n",
       "      <th>eval_loss</th>\n",
       "      <th>eval_f1_score</th>\n",
       "      <th>eval_accuracy_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.3961</td>\n",
       "      <td>7.801034</td>\n",
       "      <td>4.000352e-05</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.344694</td>\n",
       "      <td>0.789399</td>\n",
       "      <td>0.842172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.2687</td>\n",
       "      <td>9.245846</td>\n",
       "      <td>3.517721e-09</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.331557</td>\n",
       "      <td>0.803835</td>\n",
       "      <td>0.854242</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_loss  train_grad_norm  train_learning_rate  train_epoch  eval_loss  \\\n",
       "0      0.3961         7.801034         4.000352e-05          1.0   0.344694   \n",
       "1      0.2687         9.245846         3.517721e-09          2.0   0.331557   \n",
       "\n",
       "   eval_f1_score  eval_accuracy_score  \n",
       "0       0.789399             0.842172  \n",
       "1       0.803835             0.854242  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>output_dir</th>\n",
       "      <th>overwrite_output_dir</th>\n",
       "      <th>do_train</th>\n",
       "      <th>do_eval</th>\n",
       "      <th>do_predict</th>\n",
       "      <th>eval_strategy</th>\n",
       "      <th>prediction_loss_only</th>\n",
       "      <th>per_device_train_batch_size</th>\n",
       "      <th>per_device_eval_batch_size</th>\n",
       "      <th>per_gpu_train_batch_size</th>\n",
       "      <th>...</th>\n",
       "      <th>include_tokens_per_second</th>\n",
       "      <th>include_num_input_tokens_seen</th>\n",
       "      <th>neftune_noise_alpha</th>\n",
       "      <th>optim_target_modules</th>\n",
       "      <th>batch_eval_metrics</th>\n",
       "      <th>eval_on_start</th>\n",
       "      <th>use_liger_kernel</th>\n",
       "      <th>liger_kernel_config</th>\n",
       "      <th>eval_use_gather_object</th>\n",
       "      <th>average_tokens_across_devices</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aai_ModernBERT_qqp_ft</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>epoch</td>\n",
       "      <td>False</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 131 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              output_dir  overwrite_output_dir  do_train  do_eval  do_predict  \\\n",
       "0  aai_ModernBERT_qqp_ft                 False     False     True       False   \n",
       "\n",
       "  eval_strategy  prediction_loss_only  per_device_train_batch_size  \\\n",
       "0         epoch                 False                           32   \n",
       "\n",
       "   per_device_eval_batch_size per_gpu_train_batch_size  ...  \\\n",
       "0                          32                     None  ...   \n",
       "\n",
       "  include_tokens_per_second  include_num_input_tokens_seen  \\\n",
       "0                     False                          False   \n",
       "\n",
       "  neftune_noise_alpha  optim_target_modules batch_eval_metrics  eval_on_start  \\\n",
       "0                None                  None              False          False   \n",
       "\n",
       "   use_liger_kernel  liger_kernel_config  eval_use_gather_object  \\\n",
       "0             False                 None                   False   \n",
       "\n",
       "   average_tokens_across_devices  \n",
       "0                          False  \n",
       "\n",
       "[1 rows x 131 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Finetuning mnli-matched -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at output_model/modernbert-diffusion-1b and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'eos_token_id': None, 'bos_token_id': None}.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='24544' max='24544' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [24544/24544 04:33, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.838400</td>\n",
       "      <td>0.745386</td>\n",
       "      <td>0.674580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.666100</td>\n",
       "      <td>0.697327</td>\n",
       "      <td>0.703821</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: Results ::\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_grad_norm</th>\n",
       "      <th>train_learning_rate</th>\n",
       "      <th>train_epoch</th>\n",
       "      <th>eval_loss</th>\n",
       "      <th>eval_accuracy_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.8384</td>\n",
       "      <td>3.123421</td>\n",
       "      <td>4.000326e-05</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.745386</td>\n",
       "      <td>0.674580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.6661</td>\n",
       "      <td>3.934601</td>\n",
       "      <td>3.259452e-09</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.697327</td>\n",
       "      <td>0.703821</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_loss  train_grad_norm  train_learning_rate  train_epoch  eval_loss  \\\n",
       "0      0.8384         3.123421         4.000326e-05          1.0   0.745386   \n",
       "1      0.6661         3.934601         3.259452e-09          2.0   0.697327   \n",
       "\n",
       "   eval_accuracy_score  \n",
       "0             0.674580  \n",
       "1             0.703821  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>output_dir</th>\n",
       "      <th>overwrite_output_dir</th>\n",
       "      <th>do_train</th>\n",
       "      <th>do_eval</th>\n",
       "      <th>do_predict</th>\n",
       "      <th>eval_strategy</th>\n",
       "      <th>prediction_loss_only</th>\n",
       "      <th>per_device_train_batch_size</th>\n",
       "      <th>per_device_eval_batch_size</th>\n",
       "      <th>per_gpu_train_batch_size</th>\n",
       "      <th>...</th>\n",
       "      <th>include_tokens_per_second</th>\n",
       "      <th>include_num_input_tokens_seen</th>\n",
       "      <th>neftune_noise_alpha</th>\n",
       "      <th>optim_target_modules</th>\n",
       "      <th>batch_eval_metrics</th>\n",
       "      <th>eval_on_start</th>\n",
       "      <th>use_liger_kernel</th>\n",
       "      <th>liger_kernel_config</th>\n",
       "      <th>eval_use_gather_object</th>\n",
       "      <th>average_tokens_across_devices</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aai_ModernBERT_mnli-matched_ft</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>epoch</td>\n",
       "      <td>False</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 131 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       output_dir  overwrite_output_dir  do_train  do_eval  \\\n",
       "0  aai_ModernBERT_mnli-matched_ft                 False     False     True   \n",
       "\n",
       "   do_predict eval_strategy  prediction_loss_only  \\\n",
       "0       False         epoch                 False   \n",
       "\n",
       "   per_device_train_batch_size  per_device_eval_batch_size  \\\n",
       "0                           32                          32   \n",
       "\n",
       "  per_gpu_train_batch_size  ... include_tokens_per_second  \\\n",
       "0                     None  ...                     False   \n",
       "\n",
       "   include_num_input_tokens_seen neftune_noise_alpha  optim_target_modules  \\\n",
       "0                          False                None                  None   \n",
       "\n",
       "  batch_eval_metrics  eval_on_start  use_liger_kernel  liger_kernel_config  \\\n",
       "0              False          False             False                 None   \n",
       "\n",
       "   eval_use_gather_object  average_tokens_across_devices  \n",
       "0                   False                          False  \n",
       "\n",
       "[1 rows x 131 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Finetuning mnli-mismatched -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at output_model/modernbert-diffusion-1b and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'eos_token_id': None, 'bos_token_id': None}.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='24544' max='24544' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [24544/24544 04:35, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.838400</td>\n",
       "      <td>0.722191</td>\n",
       "      <td>0.688059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.665800</td>\n",
       "      <td>0.675425</td>\n",
       "      <td>0.713792</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: Results ::\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_grad_norm</th>\n",
       "      <th>train_learning_rate</th>\n",
       "      <th>train_epoch</th>\n",
       "      <th>eval_loss</th>\n",
       "      <th>eval_accuracy_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.8384</td>\n",
       "      <td>3.106269</td>\n",
       "      <td>4.000326e-05</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.722191</td>\n",
       "      <td>0.688059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.6658</td>\n",
       "      <td>4.120486</td>\n",
       "      <td>3.259452e-09</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.675425</td>\n",
       "      <td>0.713792</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_loss  train_grad_norm  train_learning_rate  train_epoch  eval_loss  \\\n",
       "0      0.8384         3.106269         4.000326e-05          1.0   0.722191   \n",
       "1      0.6658         4.120486         3.259452e-09          2.0   0.675425   \n",
       "\n",
       "   eval_accuracy_score  \n",
       "0             0.688059  \n",
       "1             0.713792  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>output_dir</th>\n",
       "      <th>overwrite_output_dir</th>\n",
       "      <th>do_train</th>\n",
       "      <th>do_eval</th>\n",
       "      <th>do_predict</th>\n",
       "      <th>eval_strategy</th>\n",
       "      <th>prediction_loss_only</th>\n",
       "      <th>per_device_train_batch_size</th>\n",
       "      <th>per_device_eval_batch_size</th>\n",
       "      <th>per_gpu_train_batch_size</th>\n",
       "      <th>...</th>\n",
       "      <th>include_tokens_per_second</th>\n",
       "      <th>include_num_input_tokens_seen</th>\n",
       "      <th>neftune_noise_alpha</th>\n",
       "      <th>optim_target_modules</th>\n",
       "      <th>batch_eval_metrics</th>\n",
       "      <th>eval_on_start</th>\n",
       "      <th>use_liger_kernel</th>\n",
       "      <th>liger_kernel_config</th>\n",
       "      <th>eval_use_gather_object</th>\n",
       "      <th>average_tokens_across_devices</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aai_ModernBERT_mnli-mismatched_ft</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>epoch</td>\n",
       "      <td>False</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 131 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          output_dir  overwrite_output_dir  do_train  do_eval  \\\n",
       "0  aai_ModernBERT_mnli-mismatched_ft                 False     False     True   \n",
       "\n",
       "   do_predict eval_strategy  prediction_loss_only  \\\n",
       "0       False         epoch                 False   \n",
       "\n",
       "   per_device_train_batch_size  per_device_eval_batch_size  \\\n",
       "0                           32                          32   \n",
       "\n",
       "  per_gpu_train_batch_size  ... include_tokens_per_second  \\\n",
       "0                     None  ...                     False   \n",
       "\n",
       "   include_num_input_tokens_seen neftune_noise_alpha  optim_target_modules  \\\n",
       "0                          False                None                  None   \n",
       "\n",
       "  batch_eval_metrics  eval_on_start  use_liger_kernel  liger_kernel_config  \\\n",
       "0              False          False             False                 None   \n",
       "\n",
       "   eval_use_gather_object  average_tokens_across_devices  \n",
       "0                   False                          False  \n",
       "\n",
       "[1 rows x 131 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Finetuning qnli -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at output_model/modernbert-diffusion-1b and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'eos_token_id': None, 'bos_token_id': None}.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6548' max='6548' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6548/6548 01:15, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.591300</td>\n",
       "      <td>0.511567</td>\n",
       "      <td>0.749039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.467400</td>\n",
       "      <td>0.499597</td>\n",
       "      <td>0.753066</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: Results ::\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_grad_norm</th>\n",
       "      <th>train_learning_rate</th>\n",
       "      <th>train_epoch</th>\n",
       "      <th>eval_loss</th>\n",
       "      <th>eval_accuracy_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.5913</td>\n",
       "      <td>7.092668</td>\n",
       "      <td>4.001222e-05</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.511567</td>\n",
       "      <td>0.749039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.4674</td>\n",
       "      <td>5.704651</td>\n",
       "      <td>1.221747e-08</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.499597</td>\n",
       "      <td>0.753066</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_loss  train_grad_norm  train_learning_rate  train_epoch  eval_loss  \\\n",
       "0      0.5913         7.092668         4.001222e-05          1.0   0.511567   \n",
       "1      0.4674         5.704651         1.221747e-08          2.0   0.499597   \n",
       "\n",
       "   eval_accuracy_score  \n",
       "0             0.749039  \n",
       "1             0.753066  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>output_dir</th>\n",
       "      <th>overwrite_output_dir</th>\n",
       "      <th>do_train</th>\n",
       "      <th>do_eval</th>\n",
       "      <th>do_predict</th>\n",
       "      <th>eval_strategy</th>\n",
       "      <th>prediction_loss_only</th>\n",
       "      <th>per_device_train_batch_size</th>\n",
       "      <th>per_device_eval_batch_size</th>\n",
       "      <th>per_gpu_train_batch_size</th>\n",
       "      <th>...</th>\n",
       "      <th>include_tokens_per_second</th>\n",
       "      <th>include_num_input_tokens_seen</th>\n",
       "      <th>neftune_noise_alpha</th>\n",
       "      <th>optim_target_modules</th>\n",
       "      <th>batch_eval_metrics</th>\n",
       "      <th>eval_on_start</th>\n",
       "      <th>use_liger_kernel</th>\n",
       "      <th>liger_kernel_config</th>\n",
       "      <th>eval_use_gather_object</th>\n",
       "      <th>average_tokens_across_devices</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aai_ModernBERT_qnli_ft</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>epoch</td>\n",
       "      <td>False</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 131 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               output_dir  overwrite_output_dir  do_train  do_eval  \\\n",
       "0  aai_ModernBERT_qnli_ft                 False     False     True   \n",
       "\n",
       "   do_predict eval_strategy  prediction_loss_only  \\\n",
       "0       False         epoch                 False   \n",
       "\n",
       "   per_device_train_batch_size  per_device_eval_batch_size  \\\n",
       "0                           32                          32   \n",
       "\n",
       "  per_gpu_train_batch_size  ... include_tokens_per_second  \\\n",
       "0                     None  ...                     False   \n",
       "\n",
       "   include_num_input_tokens_seen neftune_noise_alpha  optim_target_modules  \\\n",
       "0                          False                None                  None   \n",
       "\n",
       "  batch_eval_metrics  eval_on_start  use_liger_kernel  liger_kernel_config  \\\n",
       "0              False          False             False                 None   \n",
       "\n",
       "   eval_use_gather_object  average_tokens_across_devices  \n",
       "0                   False                          False  \n",
       "\n",
       "[1 rows x 131 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Finetuning rte -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at output_model/modernbert-diffusion-1b and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'eos_token_id': None, 'bos_token_id': None}.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='156' max='156' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [156/156 00:02, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.839400</td>\n",
       "      <td>0.773243</td>\n",
       "      <td>0.516245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.631300</td>\n",
       "      <td>0.729293</td>\n",
       "      <td>0.505415</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: Results ::\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_grad_norm</th>\n",
       "      <th>train_learning_rate</th>\n",
       "      <th>train_epoch</th>\n",
       "      <th>eval_loss</th>\n",
       "      <th>eval_accuracy_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.8394</td>\n",
       "      <td>16.390270</td>\n",
       "      <td>4.051282e-05</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.773243</td>\n",
       "      <td>0.516245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.6313</td>\n",
       "      <td>8.232226</td>\n",
       "      <td>5.128205e-07</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.729293</td>\n",
       "      <td>0.505415</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_loss  train_grad_norm  train_learning_rate  train_epoch  eval_loss  \\\n",
       "0      0.8394        16.390270         4.051282e-05          1.0   0.773243   \n",
       "1      0.6313         8.232226         5.128205e-07          2.0   0.729293   \n",
       "\n",
       "   eval_accuracy_score  \n",
       "0             0.516245  \n",
       "1             0.505415  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>output_dir</th>\n",
       "      <th>overwrite_output_dir</th>\n",
       "      <th>do_train</th>\n",
       "      <th>do_eval</th>\n",
       "      <th>do_predict</th>\n",
       "      <th>eval_strategy</th>\n",
       "      <th>prediction_loss_only</th>\n",
       "      <th>per_device_train_batch_size</th>\n",
       "      <th>per_device_eval_batch_size</th>\n",
       "      <th>per_gpu_train_batch_size</th>\n",
       "      <th>...</th>\n",
       "      <th>include_tokens_per_second</th>\n",
       "      <th>include_num_input_tokens_seen</th>\n",
       "      <th>neftune_noise_alpha</th>\n",
       "      <th>optim_target_modules</th>\n",
       "      <th>batch_eval_metrics</th>\n",
       "      <th>eval_on_start</th>\n",
       "      <th>use_liger_kernel</th>\n",
       "      <th>liger_kernel_config</th>\n",
       "      <th>eval_use_gather_object</th>\n",
       "      <th>average_tokens_across_devices</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aai_ModernBERT_rte_ft</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>epoch</td>\n",
       "      <td>False</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 131 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              output_dir  overwrite_output_dir  do_train  do_eval  do_predict  \\\n",
       "0  aai_ModernBERT_rte_ft                 False     False     True       False   \n",
       "\n",
       "  eval_strategy  prediction_loss_only  per_device_train_batch_size  \\\n",
       "0         epoch                 False                           32   \n",
       "\n",
       "   per_device_eval_batch_size per_gpu_train_batch_size  ...  \\\n",
       "0                          32                     None  ...   \n",
       "\n",
       "  include_tokens_per_second  include_num_input_tokens_seen  \\\n",
       "0                     False                          False   \n",
       "\n",
       "  neftune_noise_alpha  optim_target_modules batch_eval_metrics  eval_on_start  \\\n",
       "0                None                  None              False          False   \n",
       "\n",
       "   use_liger_kernel  liger_kernel_config  eval_use_gather_object  \\\n",
       "0             False                 None                   False   \n",
       "\n",
       "   average_tokens_across_devices  \n",
       "0                          False  \n",
       "\n",
       "[1 rows x 131 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Finetuning wnli -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at output_model/modernbert-diffusion-1b and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'eos_token_id': None, 'bos_token_id': None}.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='40' max='40' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [40/40 00:00, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.060400</td>\n",
       "      <td>0.911257</td>\n",
       "      <td>0.478873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.785200</td>\n",
       "      <td>0.921793</td>\n",
       "      <td>0.394366</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: Results ::\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_grad_norm</th>\n",
       "      <th>train_learning_rate</th>\n",
       "      <th>train_epoch</th>\n",
       "      <th>eval_loss</th>\n",
       "      <th>eval_accuracy_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0604</td>\n",
       "      <td>14.327180</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.911257</td>\n",
       "      <td>0.478873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.7852</td>\n",
       "      <td>6.899503</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.921793</td>\n",
       "      <td>0.394366</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_loss  train_grad_norm  train_learning_rate  train_epoch  eval_loss  \\\n",
       "0      1.0604        14.327180             0.000042          1.0   0.911257   \n",
       "1      0.7852         6.899503             0.000002          2.0   0.921793   \n",
       "\n",
       "   eval_accuracy_score  \n",
       "0             0.478873  \n",
       "1             0.394366  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>output_dir</th>\n",
       "      <th>overwrite_output_dir</th>\n",
       "      <th>do_train</th>\n",
       "      <th>do_eval</th>\n",
       "      <th>do_predict</th>\n",
       "      <th>eval_strategy</th>\n",
       "      <th>prediction_loss_only</th>\n",
       "      <th>per_device_train_batch_size</th>\n",
       "      <th>per_device_eval_batch_size</th>\n",
       "      <th>per_gpu_train_batch_size</th>\n",
       "      <th>...</th>\n",
       "      <th>include_tokens_per_second</th>\n",
       "      <th>include_num_input_tokens_seen</th>\n",
       "      <th>neftune_noise_alpha</th>\n",
       "      <th>optim_target_modules</th>\n",
       "      <th>batch_eval_metrics</th>\n",
       "      <th>eval_on_start</th>\n",
       "      <th>use_liger_kernel</th>\n",
       "      <th>liger_kernel_config</th>\n",
       "      <th>eval_use_gather_object</th>\n",
       "      <th>average_tokens_across_devices</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aai_ModernBERT_wnli_ft</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>epoch</td>\n",
       "      <td>False</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 131 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               output_dir  overwrite_output_dir  do_train  do_eval  \\\n",
       "0  aai_ModernBERT_wnli_ft                 False     False     True   \n",
       "\n",
       "   do_predict eval_strategy  prediction_loss_only  \\\n",
       "0       False         epoch                 False   \n",
       "\n",
       "   per_device_train_batch_size  per_device_eval_batch_size  \\\n",
       "0                           32                          32   \n",
       "\n",
       "  per_gpu_train_batch_size  ... include_tokens_per_second  \\\n",
       "0                     None  ...                     False   \n",
       "\n",
       "   include_num_input_tokens_seen neftune_noise_alpha  optim_target_modules  \\\n",
       "0                          False                None                  None   \n",
       "\n",
       "  batch_eval_metrics  eval_on_start  use_liger_kernel  liger_kernel_config  \\\n",
       "0              False          False             False                 None   \n",
       "\n",
       "   eval_use_gather_object  average_tokens_across_devices  \n",
       "0                   False                          False  \n",
       "\n",
       "[1 rows x 131 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for task in glue_tasks.keys():\n",
    "    print(f\"----- Finetuning {task} -----\")\n",
    "    train_res_df, args_df, hf_model, hf_tokenizer = finetune_glue_task(\n",
    "        task, checkpoint=checkpoint, train_subset=None, do_cleanup=True\n",
    "    )\n",
    "\n",
    "    print(\":: Results ::\")\n",
    "    display(train_res_df)\n",
    "    display(args_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "With ModernBERT encoders are back baby!  We've seen that ModernBERT-base can compete with the best of them on GLUE tasks and with a little more tuning, we'll see that ModernBERT-large can do even better.  I'm excited to see what the community will do with this model and I'm looking forward to seeing what you all build with it! We'll be exploring more of the capabilities of ModernBERT in future tutorials.\n",
    "\n",
    "Until next time, happy coding!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test All models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_bsz, val_bsz = 32, 32\n",
    "betas = (0.9, 0.98)\n",
    "n_epochs = 10\n",
    "eps = 1e-6\n",
    "\n",
    "def finetune_glue_task(\n",
    "    lr, wd, task: str, checkpoint: str = \"answerdotai/ModernBERT-base\", train_subset: int | None = None, do_cleanup: bool = True\n",
    "):  # 1. Load the task metadata\n",
    "    task_meta = glue_tasks[task]\n",
    "    train_ds_name = task_meta[\"dataset_names\"][\"train\"]\n",
    "    valid_ds_name = task_meta[\"dataset_names\"][\"valid\"]\n",
    "\n",
    "    task_inputs = task_meta[\"inputs\"]\n",
    "    n_labels = task_meta[\"n_labels\"]\n",
    "    task_metrics = task_meta[\"metric_funcs\"]\n",
    "\n",
    "    # 2. Load the dataset\n",
    "    raw_datasets = load_dataset(\"glue\", task.split(\"-\")[0] if \"-\" in task else task)\n",
    "    if train_subset is not None and len(raw_datasets[\"train\"]) > train_subset:\n",
    "        raw_datasets[\"train\"] = raw_datasets[\"train\"].shuffle(seed=42).select(range(train_subset))\n",
    "\n",
    "    id2label, label2id = get_label_maps(raw_datasets, train_ds_name)\n",
    "\n",
    "    # 3. Load the tokenizer\n",
    "    hf_tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "    tokenized_datasets = raw_datasets.map(partial(preprocess_function, task_inputs=task_inputs), batched=True)\n",
    "\n",
    "    # 4. Define the compute metrics function\n",
    "    task_compute_metrics = partial(compute_metrics, task_metrics=task_metrics)\n",
    "\n",
    "    # 5. Load the model and data collator\n",
    "    model_additional_kwargs = {\"id2label\": id2label, \"label2id\": label2id} if id2label and label2id else {}\n",
    "    hf_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        checkpoint, num_labels=n_labels, **model_additional_kwargs\n",
    "    )\n",
    "\n",
    "    hf_data_collator = DataCollatorWithPadding(tokenizer=hf_tokenizer)\n",
    "\n",
    "    # 6. Define the training arguments and trainer\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=f\"aai_ModernBERT_{task}_ft\",\n",
    "        learning_rate=lr,\n",
    "        per_device_train_batch_size=train_bsz,\n",
    "        per_device_eval_batch_size=val_bsz,\n",
    "        num_train_epochs=n_epochs,\n",
    "        lr_scheduler_type=\"linear\",\n",
    "        optim=\"adamw_torch\",\n",
    "        adam_beta1=betas[0],\n",
    "        adam_beta2=betas[1],\n",
    "        adam_epsilon=eps,\n",
    "        weight_decay=wd,\n",
    "        logging_strategy=\"epoch\",\n",
    "        eval_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        load_best_model_at_end=True,\n",
    "        bf16=True,\n",
    "        bf16_full_eval=True,\n",
    "        push_to_hub=False,\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=hf_model,\n",
    "        args=training_args,\n",
    "        train_dataset=tokenized_datasets[train_ds_name],\n",
    "        eval_dataset=tokenized_datasets[valid_ds_name],\n",
    "        processing_class=hf_tokenizer,\n",
    "        data_collator=hf_data_collator,\n",
    "        compute_metrics=task_compute_metrics,\n",
    "    )\n",
    "\n",
    "    # Add callback to trainer\n",
    "    metrics_callback = MetricsCallback()\n",
    "    trainer.add_callback(metrics_callback)\n",
    "\n",
    "    trainer.train()\n",
    "\n",
    "    # 7. Get the training results and hyperparameters\n",
    "    train_history_df = pd.DataFrame(metrics_callback.training_history[\"train\"])\n",
    "    train_history_df = train_history_df.add_prefix(\"train_\")\n",
    "    eval_history_df = pd.DataFrame(metrics_callback.training_history[\"eval\"])\n",
    "    train_res_df = pd.concat([train_history_df, eval_history_df], axis=1)\n",
    "\n",
    "    args_df = pd.DataFrame([training_args.to_dict()])\n",
    "\n",
    "    # 8. Cleanup (optional)\n",
    "    if do_cleanup:\n",
    "        cleanup(things_to_delete=[trainer, hf_model, hf_tokenizer, tokenized_datasets, raw_datasets])\n",
    "\n",
    "    return train_res_df, args_df, hf_model, hf_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Finetuning cola | lr=1e-05 | wd=1e-06 -----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1063/1063 [00:00<00:00, 18573.02 examples/s]\n",
      "Some weights of ModernBertForSequenceClassification were not initialized from the model checkpoint at output_model/modernbert-kan-1.5b and are newly initialized: ['classifier.bias', 'classifier.weight', 'head.dense.weight', 'model.layers.0.attn.Wo.weight', 'model.layers.0.attn.Wqkv.weight', 'model.layers.0.mlp.Wi.weight', 'model.layers.0.mlp.Wo.weight', 'model.layers.1.attn.Wo.weight', 'model.layers.1.attn.Wqkv.weight', 'model.layers.1.mlp.Wi.weight', 'model.layers.1.mlp.Wo.weight', 'model.layers.2.attn.Wo.weight', 'model.layers.2.attn.Wqkv.weight', 'model.layers.2.mlp.Wi.weight', 'model.layers.2.mlp.Wo.weight', 'model.layers.3.attn.Wo.weight', 'model.layers.3.attn.Wqkv.weight', 'model.layers.3.mlp.Wi.weight', 'model.layers.3.mlp.Wo.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'eos_token_id': None, 'bos_token_id': None}.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1281' max='2680' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1281/2680 00:10 < 00:11, 117.36 it/s, Epoch 4.78/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Matthews Corrcoef</th>\n",
       "      <th>Accuracy Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.678600</td>\n",
       "      <td>0.634761</td>\n",
       "      <td>-0.018741</td>\n",
       "      <td>0.657718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.620300</td>\n",
       "      <td>0.619031</td>\n",
       "      <td>0.023867</td>\n",
       "      <td>0.688399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.605400</td>\n",
       "      <td>0.616659</td>\n",
       "      <td>0.025127</td>\n",
       "      <td>0.681687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.600500</td>\n",
       "      <td>0.620850</td>\n",
       "      <td>0.046356</td>\n",
       "      <td>0.692234</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m wd \u001b[38;5;129;01min\u001b[39;00m weight_decays:\n\u001b[32m      9\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m----- Finetuning \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtask\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m | lr=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlr\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m | wd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mwd\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m -----\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m     train_res_df, args_df, hf_model, hf_tokenizer = \u001b[43mfinetune_glue_task\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_subset\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdo_cleanup\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m:: Results ::\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     15\u001b[39m     display(train_res_df)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 75\u001b[39m, in \u001b[36mfinetune_glue_task\u001b[39m\u001b[34m(lr, wd, task, checkpoint, train_subset, do_cleanup)\u001b[39m\n\u001b[32m     72\u001b[39m metrics_callback = MetricsCallback()\n\u001b[32m     73\u001b[39m trainer.add_callback(metrics_callback)\n\u001b[32m---> \u001b[39m\u001b[32m75\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     77\u001b[39m \u001b[38;5;66;03m# 7. Get the training results and hyperparameters\u001b[39;00m\n\u001b[32m     78\u001b[39m train_history_df = pd.DataFrame(metrics_callback.training_history[\u001b[33m\"\u001b[39m\u001b[33mtrain\u001b[39m\u001b[33m\"\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/development/ModernBERT/.venv/lib/python3.11/site-packages/transformers/trainer.py:2328\u001b[39m, in \u001b[36mTrainer.train\u001b[39m\u001b[34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[39m\n\u001b[32m   2326\u001b[39m         hf_hub_utils.enable_progress_bars()\n\u001b[32m   2327\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2328\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2329\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2330\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2331\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2332\u001b[39m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2333\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/development/ModernBERT/.venv/lib/python3.11/site-packages/transformers/trainer.py:2672\u001b[39m, in \u001b[36mTrainer._inner_training_loop\u001b[39m\u001b[34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[39m\n\u001b[32m   2665\u001b[39m context = (\n\u001b[32m   2666\u001b[39m     functools.partial(\u001b[38;5;28mself\u001b[39m.accelerator.no_sync, model=model)\n\u001b[32m   2667\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m i != \u001b[38;5;28mlen\u001b[39m(batch_samples) - \u001b[32m1\u001b[39m\n\u001b[32m   2668\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.accelerator.distributed_type != DistributedType.DEEPSPEED\n\u001b[32m   2669\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m contextlib.nullcontext\n\u001b[32m   2670\u001b[39m )\n\u001b[32m   2671\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[32m-> \u001b[39m\u001b[32m2672\u001b[39m     tr_loss_step = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2674\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   2675\u001b[39m     args.logging_nan_inf_filter\n\u001b[32m   2676\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[32m   2677\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m (torch.isnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch.isinf(tr_loss_step))\n\u001b[32m   2678\u001b[39m ):\n\u001b[32m   2679\u001b[39m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[32m   2680\u001b[39m     tr_loss = tr_loss + tr_loss / (\u001b[32m1\u001b[39m + \u001b[38;5;28mself\u001b[39m.state.global_step - \u001b[38;5;28mself\u001b[39m._globalstep_last_logged)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/development/ModernBERT/.venv/lib/python3.11/site-packages/transformers/trainer.py:4060\u001b[39m, in \u001b[36mTrainer.training_step\u001b[39m\u001b[34m(***failed resolving arguments***)\u001b[39m\n\u001b[32m   4057\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.accelerator.distributed_type == DistributedType.DEEPSPEED:\n\u001b[32m   4058\u001b[39m         kwargs[\u001b[33m\"\u001b[39m\u001b[33mscale_wrt_gas\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m4060\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43maccelerator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4062\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m loss.detach()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/development/ModernBERT/.venv/lib/python3.11/site-packages/accelerate/accelerator.py:2734\u001b[39m, in \u001b[36mAccelerator.backward\u001b[39m\u001b[34m(self, loss, **kwargs)\u001b[39m\n\u001b[32m   2732\u001b[39m     \u001b[38;5;28mself\u001b[39m.lomo_backward(loss, learning_rate)\n\u001b[32m   2733\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2734\u001b[39m     \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/development/ModernBERT/.venv/lib/python3.11/site-packages/torch/_tensor.py:647\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    637\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    638\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    639\u001b[39m         Tensor.backward,\n\u001b[32m    640\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    645\u001b[39m         inputs=inputs,\n\u001b[32m    646\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m647\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    648\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    649\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/development/ModernBERT/.venv/lib/python3.11/site-packages/torch/autograd/__init__.py:354\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    349\u001b[39m     retain_graph = create_graph\n\u001b[32m    351\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    352\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    353\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m354\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_tuple\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    361\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    362\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/development/ModernBERT/.venv/lib/python3.11/site-packages/torch/autograd/graph.py:829\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    827\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    828\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m829\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    830\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    831\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    832\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    833\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "checkpoint = \"output_model/modernbert-kan-1.5b\"  # \"answerdotai/ModernBERT-base\", \"answerdotai/ModernBERT-large\"\n",
    "learning_rates = [1e-5, 3e-5, 5e-5, 8e-5]\n",
    "weight_decays = [1e-6, 5e-6, 8e-6, 1e-5]\n",
    "\n",
    "hf_tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "for task in glue_tasks.keys():\n",
    "    for lr in learning_rates:\n",
    "        for wd in weight_decays:\n",
    "            print(f\"----- Finetuning {task} | lr={lr} | wd={wd} -----\")\n",
    "            train_res_df, args_df, hf_model, hf_tokenizer = finetune_glue_task(\n",
    "                lr, wd, task, checkpoint=checkpoint, train_subset=None, do_cleanup=True\n",
    "            )\n",
    "\n",
    "            print(\":: Results ::\")\n",
    "            display(train_res_df)\n",
    "            display(args_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "AcceleratorError",
     "evalue": "CUDA error: an illegal memory access was encountered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAcceleratorError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 211\u001b[39m\n\u001b[32m    207\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m all_results, all_summaries\n\u001b[32m    209\u001b[39m \u001b[38;5;66;03m# Example usage:\u001b[39;00m\n\u001b[32m    210\u001b[39m \u001b[38;5;66;03m# Run k-fold on a single task\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m211\u001b[39m results_df, summary_df = \u001b[43mkfold_glue_task\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    212\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtask\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcola\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    213\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    214\u001b[39m \u001b[43m    \u001b[49m\u001b[43mk_folds\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    215\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5e-5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    216\u001b[39m \u001b[43m    \u001b[49m\u001b[43mwd\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m8e-6\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    217\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_subset\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Use subset for testing\u001b[39;49;00m\n\u001b[32m    218\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m    220\u001b[39m \u001b[38;5;66;03m# Run k-fold on all GLUE tasks\u001b[39;00m\n\u001b[32m    221\u001b[39m \u001b[38;5;66;03m# all_results, all_summaries = run_kfold_all_glue(\u001b[39;00m\n\u001b[32m    222\u001b[39m \u001b[38;5;66;03m#     checkpoint=\"output_model/modernbert-mask-1b\",\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    226\u001b[39m \u001b[38;5;66;03m#     train_subset=None  # Use full datasets\u001b[39;00m\n\u001b[32m    227\u001b[39m \u001b[38;5;66;03m# )\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 19\u001b[39m, in \u001b[36mkfold_glue_task\u001b[39m\u001b[34m(task, checkpoint, k_folds, lr, wd, n_epochs, train_subset, random_seed)\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mkfold_glue_task\u001b[39m(\n\u001b[32m      7\u001b[39m     task: \u001b[38;5;28mstr\u001b[39m, \n\u001b[32m      8\u001b[39m     checkpoint: \u001b[38;5;28mstr\u001b[39m = \u001b[33m\"\u001b[39m\u001b[33manswerdotai/ModernBERT-base\u001b[39m\u001b[33m\"\u001b[39m, \n\u001b[32m   (...)\u001b[39m\u001b[32m     14\u001b[39m     random_seed: \u001b[38;5;28mint\u001b[39m = \u001b[32m42\u001b[39m\n\u001b[32m     15\u001b[39m ):\n\u001b[32m     16\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     17\u001b[39m \u001b[33;03m    Perform k-fold cross-validation for a GLUE task\u001b[39;00m\n\u001b[32m     18\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m     \u001b[43mset_seed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrandom_seed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     21\u001b[39m     \u001b[38;5;66;03m# 1. Load the task metadata\u001b[39;00m\n\u001b[32m     22\u001b[39m     task_meta = glue_tasks[task]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/development/ModernBERT/.venv/lib/python3.11/site-packages/transformers/trainer_utils.py:106\u001b[39m, in \u001b[36mset_seed\u001b[39m\u001b[34m(seed, deterministic)\u001b[39m\n\u001b[32m    104\u001b[39m np.random.seed(seed)\n\u001b[32m    105\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_torch_available():\n\u001b[32m--> \u001b[39m\u001b[32m106\u001b[39m     \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmanual_seed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    107\u001b[39m     torch.cuda.manual_seed_all(seed)\n\u001b[32m    108\u001b[39m     \u001b[38;5;66;03m# ^^ safe to call this function even if cuda is not available\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/development/ModernBERT/.venv/lib/python3.11/site-packages/torch/_compile.py:53\u001b[39m, in \u001b[36m_disable_dynamo.<locals>.inner\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     50\u001b[39m     disable_fn = torch._dynamo.disable(fn, recursive, wrapping=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m     51\u001b[39m     fn.__dynamo_disable = disable_fn  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdisable_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/development/ModernBERT/.venv/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py:929\u001b[39m, in \u001b[36mDisableContext.__call__.<locals>._fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    927\u001b[39m _maybe_set_eval_frame(_callback_from_stance(\u001b[38;5;28mself\u001b[39m.callback))\n\u001b[32m    928\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m929\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    930\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    931\u001b[39m     set_eval_frame(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/development/ModernBERT/.venv/lib/python3.11/site-packages/torch/random.py:46\u001b[39m, in \u001b[36mmanual_seed\u001b[39m\u001b[34m(seed)\u001b[39m\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcuda\u001b[39;00m\n\u001b[32m     45\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch.cuda._is_in_bad_fork():\n\u001b[32m---> \u001b[39m\u001b[32m46\u001b[39m     \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcuda\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmanual_seed_all\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     48\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmps\u001b[39;00m\n\u001b[32m     50\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch.mps._is_in_bad_fork():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/development/ModernBERT/.venv/lib/python3.11/site-packages/torch/cuda/random.py:131\u001b[39m, in \u001b[36mmanual_seed_all\u001b[39m\u001b[34m(seed)\u001b[39m\n\u001b[32m    128\u001b[39m         default_generator = torch.cuda.default_generators[i]\n\u001b[32m    129\u001b[39m         default_generator.manual_seed(seed)\n\u001b[32m--> \u001b[39m\u001b[32m131\u001b[39m \u001b[43m_lazy_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed_all\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/development/ModernBERT/.venv/lib/python3.11/site-packages/torch/cuda/__init__.py:341\u001b[39m, in \u001b[36m_lazy_call\u001b[39m\u001b[34m(callable, **kwargs)\u001b[39m\n\u001b[32m    339\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m _initialization_lock:\n\u001b[32m    340\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_initialized():\n\u001b[32m--> \u001b[39m\u001b[32m341\u001b[39m         \u001b[38;5;28;43mcallable\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    342\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    343\u001b[39m         \u001b[38;5;66;03m# TODO(torch_deploy): this accesses linecache, which attempts to read the\u001b[39;00m\n\u001b[32m    344\u001b[39m         \u001b[38;5;66;03m# file system to get traceback info. Patch linecache or do something\u001b[39;00m\n\u001b[32m    345\u001b[39m         \u001b[38;5;66;03m# else here if this ends up being important.\u001b[39;00m\n\u001b[32m    346\u001b[39m         \u001b[38;5;28;01mglobal\u001b[39;00m _lazy_seed_tracker\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/development/ModernBERT/.venv/lib/python3.11/site-packages/torch/cuda/random.py:129\u001b[39m, in \u001b[36mmanual_seed_all.<locals>.cb\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    127\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(device_count()):\n\u001b[32m    128\u001b[39m     default_generator = torch.cuda.default_generators[i]\n\u001b[32m--> \u001b[39m\u001b[32m129\u001b[39m     default_generator.manual_seed(seed)\n",
      "\u001b[31mAcceleratorError\u001b[39m: CUDA error: an illegal memory access was encountered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from transformers import set_seed\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def kfold_glue_task(\n",
    "    task: str, \n",
    "    checkpoint: str = \"answerdotai/ModernBERT-base\", \n",
    "    k_folds: int = 5,\n",
    "    lr: float = 8e-5,\n",
    "    wd: float = 8e-6,\n",
    "    n_epochs: int = 3,\n",
    "    train_subset: int | None = None,\n",
    "    random_seed: int = 42\n",
    "):\n",
    "    \"\"\"\n",
    "    Perform k-fold cross-validation for a GLUE task\n",
    "    \"\"\"\n",
    "    set_seed(random_seed)\n",
    "    \n",
    "    # 1. Load the task metadata\n",
    "    task_meta = glue_tasks[task]\n",
    "    train_ds_name = task_meta[\"dataset_names\"][\"train\"]\n",
    "    task_inputs = task_meta[\"inputs\"]\n",
    "    n_labels = task_meta[\"n_labels\"]\n",
    "    task_metrics = task_meta[\"metric_funcs\"]\n",
    "    \n",
    "    # 2. Load the dataset\n",
    "    raw_datasets = load_dataset(\"glue\", task.split(\"-\")[0] if \"-\" in task else task)\n",
    "    train_dataset = raw_datasets[train_ds_name]\n",
    "    \n",
    "    # Get label maps from original dataset BEFORE any splitting\n",
    "    id2label, label2id = get_label_maps(raw_datasets, train_ds_name)\n",
    "    \n",
    "    if train_subset is not None and len(train_dataset) > train_subset:\n",
    "        train_dataset = train_dataset.shuffle(seed=random_seed).select(range(train_subset))\n",
    "    \n",
    "    # 3. Convert to pandas for easier splitting\n",
    "    train_df = train_dataset.to_pandas()\n",
    "    \n",
    "    # 4. Set up k-fold split (stratified for classification, regular for regression)\n",
    "    if task == \"stsb\":  # regression task\n",
    "        kfold = KFold(n_splits=k_folds, shuffle=True, random_state=random_seed)\n",
    "        splits = list(kfold.split(train_df))\n",
    "    else:  # classification tasks\n",
    "        kfold = StratifiedKFold(n_splits=k_folds, shuffle=True, random_state=random_seed)\n",
    "        splits = list(kfold.split(train_df, train_df['label']))\n",
    "    \n",
    "    # 5. Initialize results storage\n",
    "    fold_results = []\n",
    "    \n",
    "    print(f\"Starting {k_folds}-fold CV for {task}\")\n",
    "    \n",
    "    # 6. Perform k-fold training\n",
    "    for fold, (train_idx, val_idx) in enumerate(splits):\n",
    "        print(f\"\\n--- Fold {fold + 1}/{k_folds} ---\")\n",
    "        \n",
    "        # Create fold datasets\n",
    "        fold_train_df = train_df.iloc[train_idx].reset_index(drop=True)\n",
    "        fold_val_df = train_df.iloc[val_idx].reset_index(drop=True)\n",
    "        \n",
    "        # Convert back to HF datasets and preserve original features\n",
    "        from datasets import Dataset\n",
    "        fold_train_dataset = Dataset.from_pandas(fold_train_df)\n",
    "        fold_val_dataset = Dataset.from_pandas(fold_val_df)\n",
    "        \n",
    "        # Preserve original features structure\n",
    "        if hasattr(train_dataset.features['label'], 'names'):\n",
    "            from datasets.features import ClassLabel\n",
    "            label_feature = ClassLabel(names=train_dataset.features['label'].names)\n",
    "            fold_train_dataset = fold_train_dataset.cast_column('label', label_feature)\n",
    "            fold_val_dataset = fold_val_dataset.cast_column('label', label_feature)\n",
    "        \n",
    "        # Tokenize datasets\n",
    "        hf_tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "        fold_train_tokenized = fold_train_dataset.map(\n",
    "            partial(preprocess_function, task_inputs=task_inputs), batched=True\n",
    "        )\n",
    "        fold_val_tokenized = fold_val_dataset.map(\n",
    "            partial(preprocess_function, task_inputs=task_inputs), batched=True\n",
    "        )\n",
    "        \n",
    "        # Load model with consistent label mapping\n",
    "        model_additional_kwargs = {\"id2label\": id2label, \"label2id\": label2id} if id2label and label2id else {}\n",
    "        hf_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "            checkpoint, num_labels=n_labels, **model_additional_kwargs\n",
    "        )\n",
    "        \n",
    "        # Data collator\n",
    "        hf_data_collator = DataCollatorWithPadding(tokenizer=hf_tokenizer)\n",
    "        \n",
    "        # Training arguments\n",
    "        training_args = TrainingArguments(\n",
    "            output_dir=f\"kfold_{task}_fold_{fold}\",\n",
    "            learning_rate=lr,\n",
    "            per_device_train_batch_size=32,\n",
    "            per_device_eval_batch_size=32,\n",
    "            num_train_epochs=n_epochs,\n",
    "            lr_scheduler_type=\"linear\",\n",
    "            optim=\"adamw_torch\",\n",
    "            adam_beta1=0.9,\n",
    "            adam_beta2=0.98,\n",
    "            adam_epsilon=1e-6,\n",
    "            weight_decay=wd,\n",
    "            logging_strategy=\"epoch\",\n",
    "            eval_strategy=\"epoch\",\n",
    "            save_strategy=\"no\",\n",
    "            load_best_model_at_end=False,\n",
    "            bf16=True,\n",
    "            bf16_full_eval=True,\n",
    "            push_to_hub=False,\n",
    "            report_to=None,\n",
    "            seed=random_seed,\n",
    "        )\n",
    "        \n",
    "        # Trainer\n",
    "        trainer = Trainer(\n",
    "            model=hf_model,\n",
    "            args=training_args,\n",
    "            train_dataset=fold_train_tokenized,\n",
    "            eval_dataset=fold_val_tokenized,\n",
    "            processing_class=hf_tokenizer,\n",
    "            data_collator=hf_data_collator,\n",
    "            compute_metrics=partial(compute_metrics, task_metrics=task_metrics),\n",
    "        )\n",
    "        \n",
    "        # Train\n",
    "        train_result = trainer.train()\n",
    "        \n",
    "        # Evaluate\n",
    "        eval_result = trainer.evaluate()\n",
    "        \n",
    "        # Store results\n",
    "        fold_result = {\n",
    "            'fold': fold + 1,\n",
    "            'train_loss': train_result.training_loss,\n",
    "            'eval_loss': eval_result['eval_loss'],\n",
    "        }\n",
    "        \n",
    "        # Add task-specific metrics\n",
    "        for metric_name in [m.__name__ for m in task_metrics]:\n",
    "            if f'eval_{metric_name}' in eval_result:\n",
    "                fold_result[f'eval_{metric_name}'] = eval_result[f'eval_{metric_name}']\n",
    "        \n",
    "        fold_results.append(fold_result)\n",
    "        \n",
    "        print(f\"Fold {fold + 1} results: {fold_result}\")\n",
    "        \n",
    "        # Cleanup\n",
    "        cleanup(things_to_delete=[trainer, hf_model, hf_tokenizer])\n",
    "    \n",
    "    \n",
    "    # 7. Aggregate results\n",
    "    results_df = pd.DataFrame(fold_results)\n",
    "    \n",
    "    # Calculate mean and std for each metric\n",
    "    summary_stats = {}\n",
    "    for col in results_df.columns:\n",
    "        if col != 'fold':\n",
    "            summary_stats[f'{col}_mean'] = results_df[col].mean()\n",
    "            summary_stats[f'{col}_std'] = results_df[col].std()\n",
    "    \n",
    "    summary_df = pd.DataFrame([summary_stats])\n",
    "    \n",
    "    print(f\"\\n=== {task} K-Fold Results Summary ===\")\n",
    "    display(results_df)\n",
    "    print(\"\\nMean ± Std:\")\n",
    "    display(summary_df)\n",
    "    \n",
    "    return results_df, summary_df\n",
    "\n",
    "def run_kfold_all_glue(\n",
    "    checkpoint: str = \"answerdotai/ModernBERT-base\",\n",
    "    k_folds: int = 5,\n",
    "    lr: float = 8e-5,\n",
    "    wd: float = 8e-6,\n",
    "    train_subset: int | None = None\n",
    "):\n",
    "    \"\"\"\n",
    "    Run k-fold CV on all GLUE tasks\n",
    "    \"\"\"\n",
    "    all_results = {}\n",
    "    all_summaries = {}\n",
    "    \n",
    "    for task in glue_tasks.keys():\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"Running K-Fold CV for {task.upper()}\")\n",
    "        print(f\"{'='*50}\")\n",
    "        \n",
    "        try:\n",
    "            results_df, summary_df = kfold_glue_task(\n",
    "                task=task,\n",
    "                checkpoint=checkpoint,\n",
    "                k_folds=k_folds,\n",
    "                lr=lr,\n",
    "                wd=wd,\n",
    "                train_subset=train_subset\n",
    "            )\n",
    "            \n",
    "            all_results[task] = results_df\n",
    "            all_summaries[task] = summary_df\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error with task {task}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    return all_results, all_summaries\n",
    "\n",
    "# Example usage:\n",
    "# Run k-fold on a single task\n",
    "results_df, summary_df = kfold_glue_task(\n",
    "    task=\"cola\",\n",
    "    checkpoint=checkpoint,\n",
    "    k_folds=10,\n",
    "    lr=5e-5,\n",
    "    wd=8e-6,\n",
    "    train_subset=None  # Use subset for testing\n",
    ")\n",
    "\n",
    "# Run k-fold on all GLUE tasks\n",
    "# all_results, all_summaries = run_kfold_all_glue(\n",
    "#     checkpoint=\"output_model/modernbert-mask-1b\",\n",
    "#     k_folds=5,\n",
    "#     lr=5e-5,\n",
    "#     wd=8e-6,\n",
    "#     train_subset=None  # Use full datasets\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
